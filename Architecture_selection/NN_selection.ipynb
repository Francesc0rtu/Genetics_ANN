{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection network architecture with genetics algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is inspired by the following paper: [Efficient Architecture Search for Deep Neural Networks](https://www.sciencedirect.com/science/article/pii/S1877050920303859)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from script import cifar10\n",
    "trainloader, testloader, classes = cifar10.cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define basic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('BN', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('1x1', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "#define dense layer and bottleneck layer\n",
    "class _DenseLayer(nn.Module):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('BN_1', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                                           growth_rate, kernel_size=1, stride=1,\n",
    "                                           bias=False))\n",
    "        self.add_module('relu_1', nn.ReLU(inplace=True))\n",
    "        self.add_module('BN_2', nn.BatchNorm2d(bn_size * growth_rate))\n",
    "        self.add_module('conv3', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                                           kernel_size=3, stride=1, padding=1,\n",
    "                                           bias=False)) # questo Ã¨ il cromosoma\n",
    "        self.add_module('relu_2', nn.ReLU(inplace=True))\n",
    "        self.drop_rate = float(drop_rate)\n",
    "        self.memory_efficient = memory_efficient\n",
    "\n",
    "    def bn_function(self, inputs):\n",
    "        \"Bottleneck function\"\n",
    "        # type: (List[Tensor]) -> Tensor\n",
    "        concated_features = torch.cat(inputs, 1)\n",
    "        bottleneck_output = self.relu_1(self.conv1(self.BN_1(concated_features)))  # noqa: T484\n",
    "        return bottleneck_output\n",
    "\n",
    "    def forward(self, input):  # noqa: F811\n",
    "        if torch.is_tensor(input):\n",
    "            prev_features = [input]\n",
    "        else:\n",
    "            prev_features = input\n",
    "\n",
    "        bottleneck_output = self.bn_function(prev_features)\n",
    "        new_features = self.relu_2(self.conv3(self.BN_2(bottleneck_output)))\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
    "                                     training=self.training)\n",
    "        return new_features\n",
    "\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.ModuleDict):\n",
    "    _version = 2\n",
    "\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate, memory_efficient=False):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(\n",
    "                num_input_features + i * growth_rate,\n",
    "                growth_rate=growth_rate,\n",
    "                bn_size=bn_size,\n",
    "                drop_rate=drop_rate,\n",
    "                memory_efficient=memory_efficient,\n",
    "            )\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "    def forward(self, init_features):\n",
    "        features = [init_features]\n",
    "        for name, layer in self.items():\n",
    "            new_features = layer(features)\n",
    "            features.append(new_features)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growth_rate=32, block_config=(12, 12, 12, 12),\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=10, memory_efficient=False):\n",
    "\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        #Convolution and pooling part from table-1\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\n",
    "                                padding=3, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "        ]))\n",
    "       # self.features = nn.Sequential()\n",
    "        # Add multiple denseblocks based on config \n",
    "        # for densenet-121 config: [6,12,24,16]\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                num_input_features=num_features,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                drop_rate=drop_rate,\n",
    "                memory_efficient=memory_efficient\n",
    "            )\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                # add transition layer between denseblocks to \n",
    "                # downsample\n",
    "                trans = _Transition(num_input_features=num_features,\n",
    "                                    num_output_features=num_features // 2)\n",
    "                self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    "\n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "net = DenseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define chromosomes\n",
    "\n",
    "In this version each image will feed in the whole network with different kernel size. The kernel size will be selected by the genetic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromo = [ [nn.Conv2d(3,3,kernel_size=(1,3) ), nn.ReLU(), nn.BatchNorm2d(3), nn.Conv2d(3,3,kernel_size=(3,1))], [nn.Conv2d(3,3,kernel_size=(1,7)),nn.ReLU(), nn.BatchNorm2d(3), nn.Conv2d(3,3,kernel_size=(7,1))], \n",
    "[nn.Conv2d(3,3,3)], [nn.Conv2d(3,3,3, dilation=2)], [nn.Conv2d(3,3,1)] ]   # mancano le depthwise convolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the network with the corresponding chromosome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Conv2d(3, 3, kernel_size=(1, 3), stride=(1, 1)), ReLU(), BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Conv2d(3, 3, kernel_size=(3, 1), stride=(1, 1))], [Conv2d(3, 3, kernel_size=(1, 7), stride=(1, 1)), ReLU(), BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Conv2d(3, 3, kernel_size=(7, 1), stride=(1, 1))]]\n",
      "BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "ReLU()\n",
      "AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
      "BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Conv2d(3, 3, kernel_size=(1, 3), stride=(1, 1))\n",
      "ReLU()\n",
      "BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Conv2d(3, 3, kernel_size=(3, 1), stride=(1, 1))\n",
      "ReLU()\n",
      "BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "ReLU()\n",
      "AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
      "BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Conv2d(3, 3, kernel_size=(1, 7), stride=(1, 1))\n",
      "ReLU()\n",
      "BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Conv2d(3, 3, kernel_size=(7, 1), stride=(1, 1))\n",
      "ReLU()\n"
     ]
    }
   ],
   "source": [
    "copia = copy.deepcopy(chromo)\n",
    "print(copia[0:2])\n",
    "individual = Individual(copia[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1)), Conv2d(3, 3, kernel_size=(3, 1), stride=(1, 1)), BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1)), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)], [Conv2d(3, 3, kernel_size=(1, 7), stride=(1, 1)), Conv2d(3, 3, kernel_size=(7, 1), stride=(1, 1)), BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1)), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)]]\n"
     ]
    }
   ],
   "source": [
    "print(copia[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the the output of the network:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deep_le')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a142b7d21e8575b7566c168744f24153333bb674c4e2523209192565d5391819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
