{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DENSER\n",
    "My implementation of DENSER, a method for architecture selection in neural networks. The paper can be found [here](https://arxiv.org/abs/2004.11002).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "- [ ] Implement crossover in GA class\n",
    "- [ ] Implement crossover in DSGE class\n",
    "- [ ] Implement mutation in GA class\n",
    "- [ ] Implement genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from scripts import utils, train, cifar10\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the encoder from the DENSER paper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fristly we define the lower lavel of the grammatic: a DSGE gene. This class encode a single layer from all the possible one (conv, pool, activation). \n",
    "In addition, the class compute the input channels and the output channels of the layer, which depends on the kernel size and the padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSGE_types(Enum):\n",
    "    \"Layer types for DSGE.\"\n",
    "    POOLING = 1\n",
    "    CONV = 2\n",
    "    ACTIVATION = 3\n",
    "    LINEAR = 4\n",
    "\n",
    "class DSGE_pooling(Enum):\n",
    "    \"Pooling types for DSGE.\"\n",
    "    MAX = 1\n",
    "    AVG = 2\n",
    "\n",
    "class DSGE_activation(Enum):\n",
    "    \"Activation types for DSGE.\"\n",
    "    RELU = 1\n",
    "    SIGMOID = 2\n",
    "    TANH = 3\n",
    "\n",
    "class DSGE_genes:\n",
    "    \"DSGE_encoding class. The DSGE_encoding is composed of a list of genes.\"\n",
    "    def __init__(self, type=None, c_in = None, c_out = None, param=None):\n",
    "        if type is None: # Random init, no type specified (could be pooling, conv, activation, linear)\n",
    "            self.random_init()\n",
    "        else:\n",
    "            self.init_form_encoding(type, param)\n",
    "        self.channels = {'in': c_in, 'out': c_out}\n",
    "\n",
    "        ######################################################################\n",
    "        # FORSE DA AGGIUSTARE PER IL POOLING ########################3#########\n",
    "        #######################################################################\n",
    "\n",
    "        \n",
    "        \n",
    "    def random_init(self):\n",
    "        self.type = DSGE_types(np.random.randint(1, 5))  #randomly choose a type\n",
    "        self.random_init_param()                  #randomly choose the parameters of the type\n",
    "\n",
    "    def random_init_param(self):\n",
    "        if self.type == DSGE_types.POOLING:           #randomly choose a pooling type\n",
    "            self.param = {\"pool_type\" : DSGE_pooling(np.random.randint(1, 3)), \"kernel_size\": np.random.randint(2, 5), \"stride\": np.random.randint(1, 3), \"padding\": np.random.randint(0, 2)}\n",
    "        elif self.type == DSGE_types.CONV:         #randomly choose a kernel size, stride and padding\n",
    "            self.param = {'kernel_size': np.random.randint(1, 3), 'stride': np.random.randint(1, 2), 'padding': np.random.randint(1, 2)}\n",
    "        elif self.type == DSGE_types.ACTIVATION:   #randomly choose an activation type\n",
    "            self.param = DSGE_activation(1)\n",
    "        elif self.type == DSGE_types.LINEAR:     #linear layer has no parameters\n",
    "            self.param = None\n",
    "    \n",
    "    def init_form_encoding(self, type, param=None):\n",
    "        self.type = type   #set the type\n",
    "        if param is None:   #if no parameters are specified, randomly choose them\n",
    "            self.random_init_param()\n",
    "        \n",
    "    def compute_shape(self, input_shape):\n",
    "        if self.type == DSGE_types.CONV or self.type == DSGE_types.POOLING:\n",
    "            return utils.compute_output_conv2d(input_shape, kernel_size=self.param['kernel_size'], stride=self.param['stride'], padding=self.param['padding'])\n",
    "        else:\n",
    "            return input_shape\n",
    "    def get(self):  #return the gene\n",
    "        return self.type, self.param, self.channels\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are ready to encode the outer levels, the GA types, which describe a single block of the network (a sequence of DSGE genes). A block could be a features block (conv, pool, activation) or a classifier block (linear, activation). The GA types are encoded in the class GA_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA_types(Enum):\n",
    "    \"Layer types for GA.\"\n",
    "    FEATURES = 1\n",
    "    CLASSIFICATION = 2\n",
    "    LAST_LAYER = 3\n",
    "\n",
    "class GA_genes:\n",
    "    \"GA_encoding class. The GA_encoding is composed of a list of genes.\"\n",
    "    def __init__(self, GA_type, c_in = None, c_out = None):\n",
    "        self.GA_type = GA_type #set the type\n",
    "        self.dsge_encoding = []\n",
    "        self.param  = {\"input_channels\": c_in, 'output_channels': c_out}\n",
    "        \n",
    "\n",
    "        if self.GA_type == GA_type.CLASSIFICATION :\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.LINEAR, c_in = c_in, c_out = c_out    ))\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.ACTIVATION, c_in = c_out, c_out = c_out  ))\n",
    "        if self.GA_type == GA_type.LAST_LAYER :\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.LINEAR, c_in = c_in, c_out = c_out    ))\n",
    "\n",
    "        if self.GA_type == GA_type.FEATURES:\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.CONV, c_in = c_in, c_out = c_out  ))\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.ACTIVATION, c_in = c_out, c_out = c_out ) )\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.POOLING, c_in = c_out, c_out = c_out  ))\n",
    "        self.dsge_len = len(self.dsge_encoding)    \n",
    "\n",
    "    def compute_shape(self, input_shape):\n",
    "        output_shape = input_shape\n",
    "        for i in range(self.dsge_len):\n",
    "            output_shape = self.dsge_encoding[i].compute_shape(output_shape)\n",
    "        return output_shape\n",
    "\n",
    "    def get(self):\n",
    "        return self.GA_type, self.dsge_encoding, self.param\n",
    "\n",
    "    def print(self): #print the GA_encoding\n",
    "        print( self.GA_type)\n",
    "        for i in range(len(self.dsge_encoding)):\n",
    "            print( self.dsge_encoding[i].get())\n",
    "        print(\"param: \", self.param)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we encode the whole network, the GA, which is a sequence of GA types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_encoding:\n",
    "    \"Describe the encoding of a network.\"\n",
    "    def __init__(self, num_features, num_classification, c_in , c_out):\n",
    "        self.len = num_features + num_classification #the length of the encoding is the number of features block and classification block\n",
    "        self.num_features = num_features \n",
    "        self.num_classification = num_classification\n",
    "        self.GA_encoding = []\n",
    "        \n",
    "        channels = self.init_random_channel(c_in, c_out, self.len)\n",
    "        \n",
    "\n",
    "\n",
    "        for i in range(self.num_features):\n",
    "            self.GA_encoding.append(   GA_genes(GA_types.FEATURES, c_in = channels[i][0], c_out = channels[i][1]   )    )\n",
    "            \n",
    "        k = self.num_features\n",
    "        channels[k] = ( (self.compute_shape_features(28) ** 2) * channels[k-1][1], channels[k][1])   #set the input channels of the classification block: the flatten output of the features block\n",
    "        for i in range(self.num_classification - 1):\n",
    "            self.GA_encoding.append(   GA_genes(     GA_types.CLASSIFICATION,  c_in = channels[k+i][0], c_out = channels[k+i][1]  )  )\n",
    "        self.GA_encoding.append(GA_genes( GA_types.LAST_LAYER,  c_in = channels[self.num_classification - 1 + k][0], c_out = channels[self.num_classification - 1 + k][1]  )  )\n",
    "        \n",
    "        self.param = {'input_channels': c_in ,'output_channels': c_out}\n",
    "        \n",
    "    def init_random_channel(self, C_in, C_out, len):\n",
    "        tmp = C_in\n",
    "        channels = []\n",
    "        for i in range(len-1):\n",
    "            if i == self.num_features:  #here we have to change the input channels of the classification block. The input will be the flatten output of the features block\n",
    "                tmp = \"NOT DETERMINATE\"\n",
    "            out  = np.random.randint(1,4)\n",
    "            channels.append( (tmp, out ) )\n",
    "            tmp = out\n",
    "\n",
    "        channels.append((tmp, C_out))\n",
    "        return channels\n",
    "    \n",
    "    def compute_shape_features(self, input_shape = 32):\n",
    "        output_shape = input_shape\n",
    "        for i in range(self.num_features):\n",
    "            output_shape = self.GA_encoding[i].compute_shape(output_shape)\n",
    "        return output_shape\n",
    "\n",
    "    def get(self):\n",
    "        return self.GA_encoding\n",
    "        \n",
    "    def print(self):\n",
    "        print(\"Net encoding len:\", self.len)\n",
    "        for i in range(self.len):\n",
    "            print( self.GA_encoding[i].print())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to build a network with 4 features blocks and 2 classifier blocks, with a 3 channel input (a standard RGB image) and a 10 channel output (class of CIFAR-10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net encoding len: 6\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 1, 'stride': 1, 'padding': 1}, {'in': 1, 'out': 1})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.RELU: 1>, {'in': 1, 'out': 1})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.AVG: 2>, 'kernel_size': 2, 'stride': 1, 'padding': 1}, {'in': 1, 'out': 1})\n",
      "param:  {'input_channels': 1, 'output_channels': 1}\n",
      "None\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 1, 'stride': 1, 'padding': 1}, {'in': 1, 'out': 3})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.RELU: 1>, {'in': 3, 'out': 3})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.MAX: 1>, 'kernel_size': 2, 'stride': 1, 'padding': 0}, {'in': 3, 'out': 3})\n",
      "param:  {'input_channels': 1, 'output_channels': 3}\n",
      "None\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 2, 'stride': 1, 'padding': 1}, {'in': 3, 'out': 1})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.RELU: 1>, {'in': 1, 'out': 1})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.AVG: 2>, 'kernel_size': 3, 'stride': 1, 'padding': 0}, {'in': 1, 'out': 1})\n",
      "param:  {'input_channels': 3, 'output_channels': 1}\n",
      "None\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 2, 'stride': 1, 'padding': 1}, {'in': 1, 'out': 1})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.RELU: 1>, {'in': 1, 'out': 1})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.AVG: 2>, 'kernel_size': 2, 'stride': 2, 'padding': 1}, {'in': 1, 'out': 1})\n",
      "param:  {'input_channels': 1, 'output_channels': 1}\n",
      "None\n",
      "GA_types.CLASSIFICATION\n",
      "(<DSGE_types.LINEAR: 4>, None, {'in': 289, 'out': 3})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.RELU: 1>, {'in': 3, 'out': 3})\n",
      "param:  {'input_channels': 289, 'output_channels': 3}\n",
      "None\n",
      "GA_types.LAST_LAYER\n",
      "(<DSGE_types.LINEAR: 4>, None, {'in': 3, 'out': 10})\n",
      "param:  {'input_channels': 3, 'output_channels': 10}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Net = Net_encoding( 4, 2, 1, 10 )\n",
    "Net.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the encoding to the neural network\n",
    "Now we can build the neural network module from the encoding. We have only to select the correct layer from the DSGE gene and to connect them in the correct order. All the information are contained in the Net_encoding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class _Net(nn.Module):\n",
    "    def __init__(self, Net_encod):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_list = []\n",
    "  \n",
    "\n",
    "        for i in range(Net_encod.num_features):\n",
    "            for j in range(Net_encod.GA_encoding[i].dsge_len):\n",
    "                layer = self.make_layer(Net_encod.GA_encoding[i].dsge_encoding[j])\n",
    "                self.layer_list.append(layer)\n",
    "\n",
    "        self.layer_list.append(nn.Flatten() )\n",
    "\n",
    "        for i in range(Net_encod.num_classification):\n",
    "            for j in range(Net_encod.GA_encoding[Net_encod.num_features + i].dsge_len):\n",
    "                self.layer_list.append( self.make_layer(Net_encod.GA_encoding[Net_encod.num_features + i].dsge_encoding[j]))\n",
    "        \n",
    "        self.layers = nn.Sequential(*self.layer_list)\n",
    "\n",
    "\n",
    "    def make_layer(self, dsge_encod):\n",
    "            if dsge_encod.type == DSGE_types.CONV:\n",
    "                return nn.Conv2d(dsge_encod.channels['in'], dsge_encod.channels['out'], dsge_encod.param['kernel_size'], dsge_encod.param['stride'], dsge_encod.param['padding'])\n",
    "            if dsge_encod.type == DSGE_types.LINEAR:\n",
    "                    return nn.Linear(dsge_encod.channels['in'], dsge_encod.channels['out'])\n",
    "            if dsge_encod.type == DSGE_types.ACTIVATION:\n",
    "                if dsge_encod.param == DSGE_activation.RELU:\n",
    "                    return nn.ReLU()\n",
    "                if dsge_encod.param == DSGE_activation.SIGMOID:\n",
    "                    return nn.Sigmoid()\n",
    "                if dsge_encod.param == DSGE_activation.TANH:\n",
    "                    return nn.Tanh()\n",
    "            if dsge_encod.type == DSGE_types.POOLING:\n",
    "                if dsge_encod.param[\"pool_type\"] == DSGE_pooling.MAX:\n",
    "                    return nn.MaxPool2d(dsge_encod.param['kernel_size'], dsge_encod.param['stride'], dsge_encod.param['padding'])\n",
    "                if dsge_encod.param[\"pool_type\"] == DSGE_pooling.AVG:\n",
    "                    return nn.AvgPool2d(dsge_encod.param['kernel_size'], dsge_encod.param['stride'], dsge_encod.param['padding'])\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.layers(x)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the network from the encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Net(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=1, padding=1)\n",
      "    (3): Conv2d(1, 3, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(3, 1, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): AvgPool2d(kernel_size=3, stride=1, padding=0)\n",
      "    (9): Conv2d(1, 1, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Linear(in_features=289, out_features=3, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=3, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = _Net(Net)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the network on cifar 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from scripts.train import train_model\n",
    "\n",
    "\n",
    "trainloader, testloader, classes = cifar10.cifar10()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "# We download the train and the test dataset in the given root and applying the given transforms\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,  download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,  download=True, transform=transform)\n",
    "\n",
    "batch_size=4\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,  shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,  shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 8, 0])\n",
      "tensor([[-0.3037,  0.2307, -0.0424, -0.0920,  0.0782,  0.4275,  0.7365,  0.1747,\n",
      "         -0.1774,  0.4356],\n",
      "        [-0.3037,  0.2307, -0.0424, -0.0920,  0.0782,  0.4275,  0.7365,  0.1747,\n",
      "         -0.1774,  0.4356],\n",
      "        [-0.3037,  0.2307, -0.0424, -0.0920,  0.0782,  0.4275,  0.7365,  0.1747,\n",
      "         -0.1774,  0.4356],\n",
      "        [-0.3037,  0.2307, -0.0424, -0.0920,  0.0782,  0.4275,  0.7365,  0.1747,\n",
      "         -0.1774,  0.4356]], grad_fn=<AddmmBackward0>)\n",
      "tensor(2.5210, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "images , classes = next(iter(trainloader))\n",
    "#model = _Net(Net_encoding( 2, 1, 1, 10 ))\n",
    "def imgshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "print(images.shape)\n",
    "imgshow(torchvision.utils.make_grid(images))\n",
    "print(classes)\n",
    "print(model(images))\n",
    "print(criterion(model(images), classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Net(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 9, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): AvgPool2d(kernel_size=4, stride=2, padding=0)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=225, out_features=10, bias=True)\n",
      "    (8): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = _Net(Net_encoding( 2, 1, 1, 10 ))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=( 1,1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.532\n",
      "[1,  1001] loss: 2.153\n",
      "[1,  2001] loss: 2.246\n",
      "[1,  3001] loss: 2.421\n",
      "[1,  4001] loss: 2.324\n",
      "[1,  5001] loss: 2.520\n",
      "[1,  6001] loss: 2.444\n",
      "[1,  7001] loss: 2.231\n",
      "[1,  8001] loss: 2.621\n",
      "[1,  9001] loss: 2.248\n",
      "[1, 10001] loss: 2.334\n",
      "[1, 11001] loss: 2.260\n",
      "[1, 12001] loss: 2.417\n",
      "[1, 13001] loss: 2.454\n",
      "[1, 14001] loss: 2.923\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def train(net, trainloader, epochs=2):\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 1000 == 0:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, loss.item()))\n",
    "            \n",
    "    print('Finished Training')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "train(model, trainloader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING - loss 2.236224412918091 - performance 0.25\n",
      "TRAINING - loss 2.358751121339026 - performance 0.10564435564435565\n",
      "TRAINING - loss 2.354909753632629 - performance 0.1054472763618191\n",
      "TRAINING - loss 2.3545265994203843 - performance 0.10329890036654449\n",
      "TRAINING - loss 2.3557333757626475 - performance 0.10141214696325919\n",
      "TRAINING - loss 2.356432935281459 - performance 0.10152969406118777\n",
      "TRAINING - loss 2.356002613815183 - performance 0.10227462089651725\n",
      "TRAINING - loss 2.3550927033851425 - performance 0.10166404799314384\n",
      "TRAINING - loss 2.3550973706000478 - performance 0.10179977502812149\n",
      "TRAINING - loss 2.3559946678516774 - performance 0.10193311854238418\n",
      "TRAINING - loss 2.355941690500826 - performance 0.10188981101889812\n",
      "TRAINING - loss 2.355469071868333 - performance 0.10324061448959186\n",
      "TRAINING - loss 2.3551870908710164 - performance 0.10340804932922257\n",
      "TRAINING - loss 2.3555185602092896 - performance 0.10312668256287978\n",
      "TRAINING - loss 2.355570546184878 - performance 0.10247482322691236\n",
      "Epoch 1 completed. Loss - total: 141348.05402374268 - average: 2.355800900395711; Performance: 0.10235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(141348.05402374268, 0.10235)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, trainloader, criterion, optimizer,1, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING - loss -- - performance 0.098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.098)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.train import test_model\n",
    "test_model(model, testloader, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "  with torch.no_grad():\n",
    "      for data in testloader:\n",
    "          images, labels = data\n",
    "          # calculate outputs by running images through the network\n",
    "          outputs = model.forward(images)\n",
    "          # the class with the highest energy is what we choose as prediction\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct // total\n",
    "  print(f'Accuracy of the network on the 10000 test images: {accuracy} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 9 %\n"
     ]
    }
   ],
   "source": [
    "eval(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep_le')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a142b7d21e8575b7566c168744f24153333bb674c4e2523209192565d5391819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
