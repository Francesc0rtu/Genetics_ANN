{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DENSER\n",
    "My implementation of DENSER, a method for architecture selection in neural networks. The paper can be found [here](https://arxiv.org/abs/2004.11002).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "- [ ] Implement crossover in GA class\n",
    "- [ ] Implement crossover in DSGE class\n",
    "- [ ] Implement mutation in GA class\n",
    "- [ ] Implement genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from scripts import utils, train\n",
    "from scripts.dataloader import cifar10, MINST\n",
    "import copy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the encoder from the DENSER paper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fristly we define the lower lavel of the grammatic: a DSGE gene. This class encode a single layer from all the possible one (conv, pool, activation). \n",
    "In addition, the class compute the input channels and the output channels of the layer, which depends on the kernel size and the padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSGE_types(Enum):\n",
    "    \"Layer types for DSGE.\"\n",
    "    POOLING = 1\n",
    "    CONV = 2\n",
    "    ACTIVATION = 3\n",
    "    LINEAR = 4\n",
    "\n",
    "class DSGE_pooling(Enum):\n",
    "    \"Pooling types for DSGE.\"\n",
    "    MAX = 1\n",
    "    AVG = 2\n",
    "\n",
    "class DSGE_activation(Enum):\n",
    "    \"Activation types for DSGE.\"\n",
    "    RELU = 1\n",
    "    SIGMOID = 2\n",
    "    TANH = 3\n",
    "    SOFTMAX = 4\n",
    "\n",
    "class DSGE_genes:\n",
    "    \"DSGE_encoding class. The DSGE_encoding is composed of a list of genes.\"\n",
    "    def __init__(self, type=None, c_in = None, c_out = None, param=None):\n",
    "        if type is None: # Random init, no type specified (could be pooling, conv, activation, linear)\n",
    "            self.random_init()\n",
    "        else:\n",
    "            self.init_form_encoding(type, param)\n",
    "        self.channels = {'in': c_in, 'out': c_out}\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def random_init(self):\n",
    "        self.type = DSGE_types(np.random.randint(1, 5))  #randomly choose a type\n",
    "        self.random_init_param()                  #randomly choose the parameters of the type\n",
    "\n",
    "    def random_init_param(self):\n",
    "        if self.type == DSGE_types.POOLING:           #randomly choose a pooling type\n",
    "            self.param = {\"pool_type\" : DSGE_pooling(np.random.randint(1, 3)), \"kernel_size\": np.random.randint(2, 5), \"stride\": np.random.randint(1, 3), \"padding\": np.random.randint(0, 2)}\n",
    "        elif self.type == DSGE_types.CONV:         #randomly choose a kernel size, stride and padding\n",
    "            self.param = {'kernel_size': np.random.randint(1, 9), 'stride': np.random.randint(1, 2), 'padding': np.random.randint(1, 2)}\n",
    "        elif self.type == DSGE_types.ACTIVATION:   #randomly choose an activation type\n",
    "            self.param = DSGE_activation(np.random.randint(1, 4))\n",
    "        elif self.type == DSGE_types.LINEAR:     #linear layer has no parameters\n",
    "            self.param = None\n",
    "    \n",
    "    def init_form_encoding(self, type, param=None):\n",
    "        self.type = type   #set the type\n",
    "        if param is None:   #if no parameters are specified, randomly choose them\n",
    "            self.random_init_param()\n",
    "        \n",
    "    def compute_shape(self, input_shape):\n",
    "        if self.type == DSGE_types.CONV or self.type == DSGE_types.POOLING:\n",
    "            return utils.compute_output_conv2d(input_shape, kernel_size=self.param['kernel_size'], stride=self.param['stride'], padding=self.param['padding'])\n",
    "        else:\n",
    "            return input_shape\n",
    "    def get(self):  #return the gene\n",
    "        return self.type, self.param, self.channels\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are ready to encode the outer levels, the GA types, which describe a single block of the network (a sequence of DSGE genes). A block could be a features block (conv, pool, activation) or a classifier block (linear, activation). The GA types are encoded in the class GA_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA_types(Enum):\n",
    "    \"Layer types for GA.\"\n",
    "    FEATURES = 1\n",
    "    CLASSIFICATION = 2\n",
    "    LAST_LAYER = 3\n",
    "\n",
    "class GA_genes:\n",
    "    \"GA_encoding class. The GA_encoding is composed of a list of genes.\"\n",
    "    def __init__(self, GA_type, c_in = None, c_out = None):\n",
    "        self.GA_type = GA_type #set the type\n",
    "        self.dsge_encoding = []\n",
    "        self.param  = {\"input_channels\": c_in, 'output_channels': c_out}\n",
    "        \n",
    "\n",
    "        if self.GA_type == GA_type.CLASSIFICATION :\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.LINEAR, c_in = c_in, c_out = c_out    ))\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.ACTIVATION, c_in = c_out, c_out = c_out  ))\n",
    "            \n",
    "        if self.GA_type == GA_type.LAST_LAYER :\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.LINEAR, c_in = c_in, c_out = c_out    ))\n",
    "\n",
    "        if self.GA_type == GA_type.FEATURES:\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.CONV, c_in = c_in, c_out = c_out  ))\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.ACTIVATION, c_in = c_out, c_out = c_out ) )\n",
    "            self.dsge_encoding.append(DSGE_genes(DSGE_types.POOLING, c_in = c_out, c_out = c_out  ))\n",
    "        self.dsge_len = len(self.dsge_encoding)    \n",
    "\n",
    "    def compute_shape(self, input_shape):\n",
    "        output_shape = input_shape\n",
    "        for i in range(self.dsge_len):\n",
    "            output_shape = self.dsge_encoding[i].compute_shape(output_shape)\n",
    "        return output_shape\n",
    "\n",
    "    def get(self):\n",
    "        return self.GA_type, self.dsge_encoding, self.param\n",
    "\n",
    "    def print(self): #print the GA_encoding\n",
    "        print( self.GA_type)\n",
    "        for i in range(len(self.dsge_encoding)):\n",
    "            print( self.dsge_encoding[i].get())\n",
    "        print(\"param: \", self.param)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we encode the whole network, the GA, which is a sequence of GA types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_encoding:\n",
    "    \"Describe the encoding of a network.\"\n",
    "    def __init__(self, num_features, num_classification, c_in , c_out, input_shape):\n",
    "  \n",
    "        self.GA_features = []\n",
    "        self.GA_classification = []\n",
    "        self.GA_last_layer = []\n",
    "        \n",
    "        channels = self.init_random_channel(c_in, c_out, num_features + num_classification )\n",
    "        \n",
    "\n",
    "\n",
    "        for i in range(num_features):\n",
    "            self.GA_features.append(   GA_genes(GA_types.FEATURES, c_in = channels[i][0], c_out = channels[i][1]   )    )\n",
    "            \n",
    "        k = num_features\n",
    "        channels[k] = ( (self.compute_shape_features(input_shape) ** 2) * channels[k-1][1], channels[k][1])   #set the input channels of the classification block: the flatten output of the features block\n",
    "        for i in range(num_classification - 1):\n",
    "            self.GA_classification.append(   GA_genes(     GA_types.CLASSIFICATION,  c_in = channels[k+i][0], c_out = channels[k+i][1]  )  )\n",
    "\n",
    "        self.GA_last_layer.append(GA_genes( GA_types.LAST_LAYER,  c_in = channels[self.num_classification() + k][0], c_out = c_out)  )\n",
    "        \n",
    " \n",
    "        self.param = {'input_channels': c_in ,'output_channels': c_out}\n",
    "        \n",
    "    def _len(self):\n",
    "        x =  len(self.GA_features) +  len(self.GA_classification) + 1\n",
    "        return  x #the length of the encoding is the number of features block and classification block\n",
    "    def num_features(self):\n",
    "        x = len(self.GA_features)\n",
    "        return x\n",
    "    def num_classification(self):\n",
    "        x = len(self.GA_classification) \n",
    "        return x  \n",
    "\n",
    "    def GA_encoding(self, i):\n",
    "        if i < self.num_features():\n",
    "            return self.GA_features[i]\n",
    "        elif i < self.num_features() + self.num_classification():\n",
    "            return self.GA_classification[i - self.num_features() ]\n",
    "        elif i == self.num_features() + self.num_classification():\n",
    "            return self.GA_last_layer[0]\n",
    "        else:\n",
    "            return self.GA_last_layer[0]\n",
    "\n",
    "    def init_random_channel(self, C_in, C_out, len):\n",
    "        tmp = C_in\n",
    "        channels = []\n",
    "        for i in range(len-1):\n",
    "            out  = np.random.randint(3,30)\n",
    "            channels.append( (tmp, out ) )\n",
    "            tmp = out\n",
    "\n",
    "        channels.append((tmp, C_out))\n",
    "        return channels\n",
    "    \n",
    "    def compute_shape_features(self, input_shape = 32):\n",
    "        output_shape = input_shape\n",
    "        for i in range(self.num_features()):\n",
    "            output_shape = self.GA_features[i].compute_shape(output_shape)\n",
    "        return output_shape\n",
    "\n",
    "    def get(self):\n",
    "        return self.GA_encoding\n",
    "        \n",
    "    def print(self):\n",
    "        print(\"Net encoding len:\", self._len())\n",
    "        for i in range(self._len()):\n",
    "            print( self.GA_encoding(i).print())\n",
    "\n",
    "    def print_GAlevel(self):\n",
    "        print(\"Net len:\", self._len())\n",
    "        for i in range(self._len()):\n",
    "            print(\"-\",i, self.GA_encoding(i).GA_type)\n",
    "\n",
    "    def fix_channels\n",
    "\n",
    "def GA_crossover(parent1, parent2):\n",
    "        #find cutting point\n",
    "        cut_parent1 = np.random.randint(0, parent1._len() -1)\n",
    "        cut_parent2 = np.random.randint(0, parent2._len() -1)\n",
    "        \n",
    "\n",
    "        #identify the type of the cut\n",
    "        cut1_type = parent1.GA_encoding(cut_parent1).GA_type\n",
    "        cut2_type = parent2.GA_encoding(cut_parent2).GA_type\n",
    "\n",
    "        print(\"cut1_type: \", cut1_type, \"cut\", cut_parent1)\n",
    "        print(\"cut2_type: \", cut2_type, \"cut\", cut_parent2)\n",
    "\n",
    "        if cut1_type == cut2_type and cut1_type == GA_types.FEATURES:\n",
    "            print(\"FEATURES\")\n",
    "            aux1 = copy.deepcopy(parent1.GA_features[cut_parent1:])\n",
    "            aux2 = copy.deepcopy(parent2.GA_features[cut_parent2:])\n",
    "   \n",
    "            parent1.GA_features = copy.deepcopy(parent1.GA_features[:cut_parent1])\n",
    "            parent2.GA_features = copy.deepcopy(parent2.GA_features[:cut_parent2])\n",
    "            \n",
    "            parent1.GA_features.extend(aux2)\n",
    "            parent2.GA_features.extend(aux1)\n",
    "\n",
    "            return parent1, parent2\n",
    "        if cut1_type == cut2_type and cut1_type == GA_types.CLASSIFICATION:\n",
    "            print(\"CLASSIFICATION\")\n",
    "            aux1 = copy.deepcopy(parent1.GA_classification[cut_parent1 - parent1.num_features():])\n",
    "            aux2 = copy.deepcopy(parent2.GA_classification[cut_parent2 - parent2.num_features():])\n",
    "   \n",
    "            parent1.GA_classification = copy.deepcopy(parent1.GA_classification[:cut_parent1 - parent1.num_features()])\n",
    "            parent2.GA_classification = copy.deepcopy(parent2.GA_classification[:cut_parent2 - parent2.num_features()])\n",
    "            \n",
    "            parent1.GA_classification.extend(aux2)\n",
    "            parent2.GA_classification.extend(aux1)\n",
    "\n",
    "            return parent1, parent2\n",
    "\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3,4,5]\n",
    "print(x[2:])\n",
    "print(x[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net len: 14\n",
      "- 0 GA_types.FEATURES\n",
      "- 1 GA_types.FEATURES\n",
      "- 2 GA_types.FEATURES\n",
      "- 3 GA_types.FEATURES\n",
      "- 4 GA_types.FEATURES\n",
      "- 5 GA_types.FEATURES\n",
      "- 6 GA_types.FEATURES\n",
      "- 7 GA_types.FEATURES\n",
      "- 8 GA_types.FEATURES\n",
      "- 9 GA_types.FEATURES\n",
      "- 10 GA_types.FEATURES\n",
      "- 11 GA_types.FEATURES\n",
      "- 12 GA_types.CLASSIFICATION\n",
      "- 13 GA_types.LAST_LAYER\n",
      "Net len: 5\n",
      "- 0 GA_types.FEATURES\n",
      "- 1 GA_types.FEATURES\n",
      "- 2 GA_types.FEATURES\n",
      "- 3 GA_types.CLASSIFICATION\n",
      "- 4 GA_types.LAST_LAYER\n",
      "cut1_type:  GA_types.FEATURES cut 7\n",
      "cut2_type:  GA_types.FEATURES cut 0\n",
      "FEATURES\n",
      "Net len: 12\n",
      "- 0 GA_types.FEATURES\n",
      "- 1 GA_types.FEATURES\n",
      "- 2 GA_types.FEATURES\n",
      "- 3 GA_types.FEATURES\n",
      "- 4 GA_types.FEATURES\n",
      "- 5 GA_types.FEATURES\n",
      "- 6 GA_types.FEATURES\n",
      "- 7 GA_types.FEATURES\n",
      "- 8 GA_types.FEATURES\n",
      "- 9 GA_types.FEATURES\n",
      "- 10 GA_types.CLASSIFICATION\n",
      "- 11 GA_types.LAST_LAYER\n",
      "Net len: 7\n",
      "- 0 GA_types.FEATURES\n",
      "- 1 GA_types.FEATURES\n",
      "- 2 GA_types.FEATURES\n",
      "- 3 GA_types.FEATURES\n",
      "- 4 GA_types.FEATURES\n",
      "- 5 GA_types.CLASSIFICATION\n",
      "- 6 GA_types.LAST_LAYER\n"
     ]
    }
   ],
   "source": [
    "parent1 = Net_encoding(12, 2, 3, 10, 32)\n",
    "parent2 = Net_encoding(3, 2, 3, 10, 32)\n",
    "parent1.print_GAlevel()\n",
    "parent2.print_GAlevel()\n",
    "child1, child2 = GA_crossover(parent1, parent2)\n",
    "child1.print_GAlevel()\n",
    "child2.print_GAlevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to build a network with 4 features blocks and 2 classifier blocks, with a 3 channel input (a standard RGB image) and a 10 channel output (class of CIFAR-10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net encoding len: 5\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 1, 'stride': 1, 'padding': 1}, {'in': 3, 'out': 12})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.SIGMOID: 2>, {'in': 12, 'out': 12})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.MAX: 1>, 'kernel_size': 3, 'stride': 2, 'padding': 0}, {'in': 12, 'out': 12})\n",
      "param:  {'input_channels': 3, 'output_channels': 12}\n",
      "None\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 8, 'stride': 1, 'padding': 1}, {'in': 12, 'out': 11})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.SIGMOID: 2>, {'in': 11, 'out': 11})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.MAX: 1>, 'kernel_size': 3, 'stride': 2, 'padding': 1}, {'in': 11, 'out': 11})\n",
      "param:  {'input_channels': 12, 'output_channels': 11}\n",
      "None\n",
      "GA_types.CLASSIFICATION\n",
      "(<DSGE_types.LINEAR: 4>, None, {'in': 396, 'out': 15})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.RELU: 1>, {'in': 15, 'out': 15})\n",
      "param:  {'input_channels': 396, 'output_channels': 15}\n",
      "None\n",
      "GA_types.CLASSIFICATION\n",
      "(<DSGE_types.LINEAR: 4>, None, {'in': 15, 'out': 13})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.TANH: 3>, {'in': 13, 'out': 13})\n",
      "param:  {'input_channels': 15, 'output_channels': 13}\n",
      "None\n",
      "GA_types.LAST_LAYER\n",
      "(<DSGE_types.LINEAR: 4>, None, {'in': 13, 'out': 10})\n",
      "param:  {'input_channels': 13, 'output_channels': 10}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "netcode = Net_encoding( 2, 3, 3, 10, 32 )\n",
    "netcode.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the encoding to the neural network\n",
    "Now we can build the neural network module from the encoding. We have only to select the correct layer from the DSGE gene and to connect them in the correct order. All the information are contained in the Net_encoding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, Net_encod):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_list = []\n",
    "  \n",
    "\n",
    "        for i in range(Net_encod.num_features()):\n",
    "            for j in range(Net_encod.GA_encoding(i).dsge_len):\n",
    "                layer = self.make_layer(Net_encod.GA_encoding(i).dsge_encoding[j])\n",
    "                self.layer_list.append(layer)\n",
    "\n",
    "        self.layer_list.append(nn.Flatten() )\n",
    "\n",
    "        for i in range(Net_encod.num_classification()):\n",
    "            for j in range(Net_encod.GA_encoding(Net_encod.num_features() + i).dsge_len):\n",
    "                self.layer_list.append( self.make_layer(Net_encod.GA_encoding(Net_encod.num_features() + i).dsge_encoding[j]))\n",
    "        self.layer_list.append(self.make_layer(Net_encod.GA_last_layer[0].dsge_encoding[0]) )\n",
    "        self.layers = nn.Sequential(*self.layer_list)\n",
    "\n",
    "\n",
    "    def make_layer(self, dsge_encod):\n",
    "            if dsge_encod.type == DSGE_types.CONV:\n",
    "                return nn.Conv2d(dsge_encod.channels['in'], dsge_encod.channels['out'], dsge_encod.param['kernel_size'], dsge_encod.param['stride'], dsge_encod.param['padding'])\n",
    "            if dsge_encod.type == DSGE_types.LINEAR:\n",
    "                    return nn.Linear(dsge_encod.channels['in'], dsge_encod.channels['out'])\n",
    "            if dsge_encod.type == DSGE_types.ACTIVATION:\n",
    "                if dsge_encod.param == DSGE_activation.RELU:\n",
    "                    return nn.ReLU()\n",
    "                if dsge_encod.param == DSGE_activation.SIGMOID:\n",
    "                    return nn.Sigmoid()\n",
    "                if dsge_encod.param == DSGE_activation.TANH:\n",
    "                    return nn.Tanh()\n",
    "            if dsge_encod.type == DSGE_types.POOLING:\n",
    "                if dsge_encod.param[\"pool_type\"] == DSGE_pooling.MAX:\n",
    "                    return nn.MaxPool2d(dsge_encod.param['kernel_size'], dsge_encod.param['stride'], dsge_encod.param['padding'])\n",
    "                if dsge_encod.param[\"pool_type\"] == DSGE_pooling.AVG:\n",
    "                    return nn.AvgPool2d(dsge_encod.param['kernel_size'], dsge_encod.param['stride'], dsge_encod.param['padding'])\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the network on MINST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "# We download the train and the test dataset in the given root and applying the given transforms\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,  download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,  download=True, transform=transform)\n",
    "\n",
    "batch_size=4\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,  shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,  shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 2, 8])\n",
      "tensor([[ 0.5459,  0.1886,  0.0196,  0.2765, -0.3400,  0.6505, -0.3015, -0.7627,\n",
      "          0.1804, -0.2225],\n",
      "        [ 0.5484,  0.1888,  0.0194,  0.2740, -0.3411,  0.6529, -0.3015, -0.7629,\n",
      "          0.1798, -0.2212],\n",
      "        [ 0.5461,  0.1885,  0.0230,  0.2776, -0.3396,  0.6535, -0.2989, -0.7637,\n",
      "          0.1814, -0.2201],\n",
      "        [ 0.5480,  0.1899,  0.0217,  0.2778, -0.3402,  0.6520, -0.3020, -0.7630,\n",
      "          0.1815, -0.2222]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "images , classes = next(iter(trainloader))\n",
    "netcode = Net_encoding( 4, 1, 1, 10 , 28)\n",
    "model = Net(netcode)\n",
    "def imgshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "print(images.shape)\n",
    "imgshow(torchvision.utils.make_grid(images))\n",
    "print(classes)\n",
    "print(model(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net encoding len: 5\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 6, 'stride': 1, 'padding': 1}, {'in': 1, 'out': 16})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.SIGMOID: 2>, {'in': 16, 'out': 16})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.MAX: 1>, 'kernel_size': 2, 'stride': 1, 'padding': 0}, {'in': 16, 'out': 16})\n",
      "param:  {'input_channels': 1, 'output_channels': 16}\n",
      "None\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 8, 'stride': 1, 'padding': 1}, {'in': 16, 'out': 16})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.TANH: 3>, {'in': 16, 'out': 16})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.AVG: 2>, 'kernel_size': 4, 'stride': 1, 'padding': 0}, {'in': 16, 'out': 16})\n",
      "param:  {'input_channels': 16, 'output_channels': 16}\n",
      "None\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 1, 'stride': 1, 'padding': 1}, {'in': 16, 'out': 12})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.RELU: 1>, {'in': 12, 'out': 12})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.MAX: 1>, 'kernel_size': 4, 'stride': 2, 'padding': 0}, {'in': 12, 'out': 12})\n",
      "param:  {'input_channels': 16, 'output_channels': 12}\n",
      "None\n",
      "GA_types.FEATURES\n",
      "(<DSGE_types.CONV: 2>, {'kernel_size': 2, 'stride': 1, 'padding': 1}, {'in': 12, 'out': 5})\n",
      "(<DSGE_types.ACTIVATION: 3>, <DSGE_activation.TANH: 3>, {'in': 5, 'out': 5})\n",
      "(<DSGE_types.POOLING: 1>, {'pool_type': <DSGE_pooling.MAX: 1>, 'kernel_size': 3, 'stride': 2, 'padding': 1}, {'in': 5, 'out': 5})\n",
      "param:  {'input_channels': 12, 'output_channels': 5}\n",
      "None\n",
      "GA_types.LAST_LAYER\n",
      "(<DSGE_types.LINEAR: 4>, None, {'in': 125, 'out': 10})\n",
      "param:  {'input_channels': 125, 'output_channels': 10}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "netcode.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, classes = cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model with an architecture selected with the DENSER grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(netcode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train import train, eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:34<00:00, 132.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 94 %\n"
     ]
    }
   ],
   "source": [
    "train(model, trainloader, device=\"cuda\")\n",
    "eval(model, testloader, device=\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep_le')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a142b7d21e8575b7566c168744f24153333bb674c4e2523209192565d5391819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
