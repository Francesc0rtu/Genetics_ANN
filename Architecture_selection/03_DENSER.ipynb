{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DENSER\n",
    "My implementation of DENSER, a method for architecture selection in neural networks. The paper can be found [here](https://arxiv.org/abs/2004.11002).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "- [ ] Implement crossover in GA class\n",
    "- [ ] Implement crossover in DSGE class\n",
    "- [ ] Implement mutation in GA class\n",
    "- [ ] Implement genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/envs/deep_le/lib/python3.9/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809662/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from scripts import utils, train\n",
    "from scripts.dataloader import cifar10, MINST\n",
    "import copy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the encoder from the DENSER paper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fristly we define the lower lavel of the grammatic: a DSGE gene. This class encode a single layer from all the possible one (conv, pool, activation). \n",
    "In addition, the class compute the input channels and the output channels of the layer, which depends on the kernel size and the padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer_type(Enum):\n",
    "    \"Layer types for DSGE.\"\n",
    "    POOLING = 1\n",
    "    CONV = 2\n",
    "    ACTIVATION = 3\n",
    "    LINEAR = 4\n",
    "\n",
    "class pool(Enum):\n",
    "    \"Pooling types for DSGE.\"\n",
    "    MAX = 1\n",
    "    AVG = 2\n",
    "\n",
    "class activation(Enum):\n",
    "    \"Activation types for DSGE.\"\n",
    "    RELU = 1\n",
    "    SIGMOID = 2\n",
    "    TANH = 3\n",
    "    SOFTMAX = 4\n",
    "\n",
    "class Layer:\n",
    "    \"Layer class. \"\n",
    "    def __init__(self, type=None, c_in = None, c_out = None, param=None):\n",
    "        if type is None: # Random init, no type specified (could be pooling, conv, activation, linear)\n",
    "            self.random_init()\n",
    "        else:\n",
    "            self.init_form_encoding(type, param)\n",
    "        self.channels = {'in': c_in, 'out': c_out}\n",
    "        \n",
    "        \n",
    "    def random_init(self):\n",
    "        self.type = layer_type(np.random.randint(1, 5))  #randomly choose a type\n",
    "        self.random_init_param()                  #randomly choose the parameters of the type\n",
    "\n",
    "    def random_init_param(self):\n",
    "        if self.type == layer_type.POOLING:           #randomly choose a pooling type\n",
    "            self.param = {\"pool_type\" : pool(np.random.randint(1, 3)), \"kernel_size\": np.random.randint(2, 5), \"stride\": np.random.randint(1, 3), \"padding\": np.random.randint(0, 2)}\n",
    "        elif self.type == layer_type.CONV:         #randomly choose a kernel size, stride and padding\n",
    "            self.param = {'kernel_size': np.random.randint(1, 3), 'stride': np.random.randint(1, 2), 'padding': np.random.randint(1, 2)}\n",
    "        elif self.type == layer_type.ACTIVATION:   #randomly choose an activation type\n",
    "            self.param = activation(np.random.randint(1, 4))\n",
    "        elif self.type == layer_type.LINEAR:     #linear layer has no parameters\n",
    "            self.param = None\n",
    "    \n",
    "    def init_form_encoding(self, type, param=None):\n",
    "        self.type = type   #set the type\n",
    "        if param is None:   #if no parameters are specified, randomly choose them\n",
    "            self.random_init_param()\n",
    "        \n",
    "    def compute_shape(self, input_shape):\n",
    "        if self.type == layer_type.CONV or self.type == layer_type.POOLING:\n",
    "            return utils.compute_output_conv2d(input_shape, kernel_size=self.param['kernel_size'], stride=self.param['stride'], padding=self.param['padding'])\n",
    "        else:\n",
    "            return input_shape\n",
    "    def fix_channels(self, c_in=None, c_out=None):\n",
    "        if c_in is not None:\n",
    "            self.channels['in'] = c_in\n",
    "            if self.type != layer_type.CONV and self.type != layer_type.LINEAR:\n",
    "                self.channels['out'] = c_in\n",
    "        if c_out is not None:\n",
    "            self.channels['out'] = c_out\n",
    "            if self.type != layer_type.CONV and self.type != layer_type.LINEAR:\n",
    "                self.channels['in'] = c_out\n",
    "    def get(self):  #return the gene\n",
    "        return self.type, self.param, self.channels\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are ready to encode the outer levels, the GA types, which describe a single block of the network (a sequence of DSGE genes). A block could be a features block (conv, pool, activation) or a classifier block (linear, activation). The GA types are encoded in the class M_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class module_types(Enum):\n",
    "    \"Layer types for GA.\"\n",
    "    FEATURES = 1\n",
    "    CLASSIFICATION = 2\n",
    "    LAST_LAYER = 3\n",
    "\n",
    "class Module:\n",
    "    \"GA_encoding class. The GA_encoding is composed of a list of genes.\"\n",
    "    def __init__(self, M_type, c_in = None, c_out = None):\n",
    "        self.M_type = M_type #set the type\n",
    "        self.layers = []\n",
    "        self.param  = {\"input_channels\": c_in, 'output_channels': c_out}\n",
    "        \n",
    "\n",
    "        if self.M_type == module_types.CLASSIFICATION :\n",
    "            self.layers.append(Layer(layer_type.LINEAR, c_in = c_in, c_out = c_out    ))\n",
    "            self.layers.append(Layer(layer_type.ACTIVATION, c_in = c_out, c_out = c_out  ))\n",
    "            \n",
    "        if self.M_type == module_types.LAST_LAYER :\n",
    "            self.layers.append(Layer(layer_type.LINEAR, c_in = c_in, c_out = c_out    ))\n",
    "\n",
    "        if self.M_type == module_types.FEATURES:\n",
    "            self.layers.append(Layer(layer_type.CONV, c_in = c_in, c_out = c_out  ))\n",
    "            self.layers.append(Layer(layer_type.ACTIVATION, c_in = c_out, c_out = c_out ) )\n",
    "            self.layers.append(Layer(layer_type.POOLING, c_in = c_out, c_out = c_out  ))\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.layers)  \n",
    "           \n",
    "\n",
    "    def compute_shape(self, input_shape):\n",
    "        output_shape = input_shape\n",
    "        for i in range(self.len()):\n",
    "            output_shape = self.layers[i].compute_shape(output_shape)\n",
    "        return output_shape\n",
    "\n",
    "    def fix_channels(self,c_in=None, c_out=None):\n",
    "        \"fix the channels of the layers\"\n",
    "        if (c_out is not None):\n",
    "            for i in range(self.len()):\n",
    "                self.layers[i].fix_channels(c_out=c_out)\n",
    "\n",
    "            self.param['output_channels'] = c_out\n",
    "        elif(c_in is not None):\n",
    "            self.layers[0].fix_channels(c_in=c_in)\n",
    "            self.param['input_channels'] = c_in\n",
    "\n",
    "    def get(self):\n",
    "        return self.M_type, self.layers, self.param\n",
    "\n",
    "    def print(self): #print the GA_encoding\n",
    "        print( self.M_type)\n",
    "        for i in range(len(self.layers)):\n",
    "            print( self.layers[i].get())\n",
    "        print(\"param: \", self.param)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we encode the whole network, the GA, which is a sequence of GA types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_encoding:\n",
    "    \"Describe the encoding of a network.\"\n",
    "    def __init__(self, len_features, len_classification, c_in , c_out, input_shape):\n",
    "  \n",
    "        self.features = []\n",
    "        self.classification = []\n",
    "        self.last_layer = []\n",
    "        self.input_shape = input_shape\n",
    "        channels = self.init_random_channel(c_in, c_out, len_features + len_classification + 1 )\n",
    "        \n",
    "\n",
    "\n",
    "        for i in range(len_features):\n",
    "            self.features.append(   Module(module_types.FEATURES, c_in = channels[i][0], c_out = channels[i][1]   )    )\n",
    "            \n",
    "        k = len_features\n",
    "        channels[k] = ( (self.compute_shape_features(self.input_shape) ** 2) * channels[k-1][1], channels[k][1])   #set the input channels of the classification block: the flatten output of the features block\n",
    "        for i in range(len_classification ):\n",
    "            self.classification.append(   Module(     module_types.CLASSIFICATION,  c_in = channels[k+i][0], c_out = channels[k+i][1]  )  )\n",
    "\n",
    "        self.last_layer.append(Module( module_types.LAST_LAYER,  c_in = channels[self.len_classification() + k][0], c_out = c_out)  )\n",
    "        \n",
    " \n",
    "        self.param = {'input_channels': c_in ,'output_channels': c_out}\n",
    "        \n",
    "    def _len(self):\n",
    "        x =  len(self.features) +  len(self.classification) + 1\n",
    "        return  x #the length of the encoding is the number of features block and classification block\n",
    "    def len_features(self):\n",
    "        x = len(self.features)\n",
    "        return x\n",
    "    def len_classification(self):\n",
    "        x = len(self.classification) \n",
    "        return x  \n",
    "\n",
    "    def GA_encoding(self, i):\n",
    "        \"Give the module at position i\"\n",
    "        if i < self.len_features():\n",
    "            return self.features[i]\n",
    "        elif i < self.len_features() + self.len_classification():\n",
    "            return self.classification[i - self.len_features() ]\n",
    "        elif i == self.len_features() + self.len_classification():\n",
    "            return self.last_layer[0]\n",
    "        else:\n",
    "            return self.last_layer[0]\n",
    "\n",
    "    def init_random_channel(self, C_in, C_out, len):\n",
    "        tmp = C_in\n",
    "        channels = []\n",
    "        for i in range(len-1):\n",
    "            out  = np.random.randint(7,30)\n",
    "            channels.append( (tmp, out ) )\n",
    "            tmp = out\n",
    "\n",
    "        channels.append((tmp, C_out))\n",
    "        return channels\n",
    "    \n",
    "    def compute_shape_features(self, input_shape = 32):\n",
    "        \"like the forward pass, compute the output shape of the features block\"\n",
    "        output_shape = input_shape\n",
    "        for i in range(self.len_features()):\n",
    "            output_shape = self.features[i].compute_shape(output_shape)\n",
    "        return output_shape\n",
    "\n",
    "    def get(self):\n",
    "        return self.GA_encoding\n",
    "        \n",
    "    def print(self):\n",
    "        print(\"Net encoding len:\", self._len())\n",
    "        for i in range(self._len()):\n",
    "            print( self.GA_encoding(i).print())\n",
    "\n",
    "    def print_GAlevel(self):\n",
    "        \"print only if the module is FEATURES or CLASSIFICATION\"\n",
    "        print(\"Net len:\", self._len())\n",
    "        for i in range(self._len()):\n",
    "            print(\"-\",i, self.GA_encoding(i).M_type)\n",
    "\n",
    "\n",
    "    def fix_channels(self, cut1, cut2):\n",
    "        \"Given a new list of modules between cut1 and cut2, fix the channels of the modules\"\n",
    "        if cut1 != 0:\n",
    "            c_out = self.GA_encoding(cut1-1).param['output_channels']\n",
    "            c_in = self.GA_encoding(cut1).param['input_channels']\n",
    "            new = min (c_in, c_out)\n",
    "            self.GA_encoding(cut1-1).fix_channels(c_out = new)\n",
    "            self.GA_encoding(cut1).fix_channels(c_in = new)\n",
    "\n",
    "            c_out = self.GA_encoding(cut2-1).param['output_channels']\n",
    "            c_in = self.GA_encoding(cut2).param['input_channels']\n",
    "            new = min (c_in, c_out)\n",
    "            self.GA_encoding(cut2-1).fix_channels(c_out = new)\n",
    "            self.GA_encoding(cut2).fix_channels(c_in = new)\n",
    "        last_in = (self.compute_shape_features(self.input_shape) ** 2) * self.features[-1].param['output_channels']\n",
    "        self.classification[0].fix_channels(c_in = last_in)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def GA_crossover(parent1, parent2):\n",
    "        \"cut the parent1 and parent2 at random position and swap the two parts\"\n",
    "        #find cutting point\n",
    "        cut_parent1 = np.random.randint(0, parent1._len() -1)\n",
    "        cut_parent2 = np.random.randint(0, parent2._len() -1)\n",
    "        \n",
    "        #identify the type of the cut\n",
    "        cut1_type = parent1.GA_encoding(cut_parent1).M_type\n",
    "        cut2_type = parent2.GA_encoding(cut_parent2).M_type\n",
    "\n",
    "        if cut1_type == module_types.FEATURES and cut2_type == module_types.CLASSIFICATION or cut_parent1==0 or cut_parent2==0:\n",
    "            \n",
    "            return parent1, parent2\n",
    "\n",
    "        if cut1_type == cut2_type and cut1_type == module_types.FEATURES:\n",
    "            print(\"FEATURES\")\n",
    "            aux1 = copy.deepcopy(parent1.features[cut_parent1:])\n",
    "            aux2 = copy.deepcopy(parent2.features[cut_parent2:])\n",
    "   \n",
    "            parent1.features = copy.deepcopy(parent1.features[:cut_parent1])\n",
    "            parent2.features = copy.deepcopy(parent2.features[:cut_parent2])\n",
    "            \n",
    "            parent1.features.extend(aux2)\n",
    "            parent2.features.extend(aux1)\n",
    "            parent1.fix_channels(cut_parent1, parent1.len_features())\n",
    "            parent2.fix_channels(cut_parent2, parent2.len_features())\n",
    "\n",
    "            return parent1, parent2\n",
    "        if cut1_type == cut2_type and cut1_type == module_types.CLASSIFICATION:\n",
    "            print(\"CLASSIFICATION\")\n",
    "            aux1 = copy.deepcopy(parent1.classification[cut_parent1 - parent1.len_features():])\n",
    "            aux2 = copy.deepcopy(parent2.classification[cut_parent2 - parent2.len_features():])\n",
    "   \n",
    "            parent1.classification = copy.deepcopy(parent1.classification[:cut_parent1 - parent1.len_features()])\n",
    "            parent2.classification = copy.deepcopy(parent2.classification[:cut_parent2 - parent2.len_features()])\n",
    "            \n",
    "            parent1.classification.extend(aux2)\n",
    "            parent2.classification.extend(aux1)\n",
    "            parent1.fix_channels(cut_parent1, parent1.len_features() + parent1.len_classification())\n",
    "            parent2.fix_channels(cut_parent2, parent2.len_features() + parent2.len_classification())\n",
    "            return parent1, parent2\n",
    "\n",
    "        return parent1 , parent2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net len: 6\n",
      "- 0 module_types.FEATURES\n",
      "- 1 module_types.FEATURES\n",
      "- 2 module_types.FEATURES\n",
      "- 3 module_types.FEATURES\n",
      "- 4 module_types.CLASSIFICATION\n",
      "- 5 module_types.LAST_LAYER\n",
      "Net len: 5\n",
      "- 0 module_types.FEATURES\n",
      "- 1 module_types.FEATURES\n",
      "- 2 module_types.FEATURES\n",
      "- 3 module_types.CLASSIFICATION\n",
      "- 4 module_types.LAST_LAYER\n"
     ]
    }
   ],
   "source": [
    "parent1 = Net_encoding(4, 1, 1, 10, 28)\n",
    "parent2 = Net_encoding(3, 1, 1, 10, 28)\n",
    "parent1.print_GAlevel()\n",
    "parent2.print_GAlevel()\n",
    "child1, child2 = GA_crossover(parent1, parent2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to build a network with 4 features blocks and 2 classifier blocks, with a 3 channel input (a standard RGB image) and a 10 channel output (class of CIFAR-10):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the encoding to the neural network\n",
    "Now we can build the neural network module from the encoding. We have only to select the correct layer from the DSGE gene and to connect them in the correct order. All the information are contained in the Net_encoding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, Net_encod):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_list = []\n",
    "        \n",
    "        for i in range(Net_encod.len_features()):\n",
    "            for j in range(Net_encod.GA_encoding(i).len()):\n",
    "                layer = self.make_layer(Net_encod.GA_encoding(i).layers[j])\n",
    "                self.layer_list.append(layer)\n",
    "\n",
    "        self.layer_list.append(nn.Flatten() )\n",
    "\n",
    "        for i in range(Net_encod.len_classification()):\n",
    "            for j in range(Net_encod.GA_encoding(Net_encod.len_features() + i).len()):\n",
    "                self.layer_list.append( self.make_layer(Net_encod.GA_encoding(Net_encod.len_features() + i).layers[j]))\n",
    "        self.layer_list.append(self.make_layer(Net_encod.last_layer[0].layers[0]) )\n",
    "        self.layers = nn.Sequential(*self.layer_list)\n",
    "\n",
    "\n",
    "    def make_layer(self, dsge_encod):\n",
    "            if dsge_encod.type == layer_type.CONV:\n",
    "                return nn.Conv2d(dsge_encod.channels['in'], dsge_encod.channels['out'], dsge_encod.param['kernel_size'], dsge_encod.param['stride'], dsge_encod.param['padding'])\n",
    "            if dsge_encod.type == layer_type.LINEAR:\n",
    "                    return nn.Linear(dsge_encod.channels['in'], dsge_encod.channels['out'])\n",
    "            if dsge_encod.type == layer_type.ACTIVATION:\n",
    "                if dsge_encod.param == activation.RELU:\n",
    "                    return nn.ReLU()\n",
    "                if dsge_encod.param == activation.SIGMOID:\n",
    "                    return nn.Sigmoid()\n",
    "                if dsge_encod.param == activation.TANH:\n",
    "                    return nn.Tanh()\n",
    "            if dsge_encod.type == layer_type.POOLING:\n",
    "                if dsge_encod.param[\"pool_type\"] == pool.MAX:\n",
    "                    return nn.MaxPool2d(dsge_encod.param['kernel_size'], dsge_encod.param['stride'], dsge_encod.param['padding'])\n",
    "                if dsge_encod.param[\"pool_type\"] == pool.AVG:\n",
    "                    return nn.AvgPool2d(dsge_encod.param['kernel_size'], dsge_encod.param['stride'], dsge_encod.param['padding'])\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layer_list)):\n",
    "            # print(\"in\", i,self.layer_list[i], x.shape)\n",
    "            x = self.layer_list[i](x)\n",
    "            # print(\"out\", x.shape)\n",
    "        return x\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the network on MINST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "# We download the train and the test dataset in the given root and applying the given transforms\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,  download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,  download=True, transform=transform)\n",
    "\n",
    "batch_size=4\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,  shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,  shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 0, 0, 2])\n",
      "in 0 Conv2d(1, 20, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1)) torch.Size([4, 1, 28, 28])\n",
      "out torch.Size([4, 20, 29, 29])\n",
      "in 1 ReLU() torch.Size([4, 20, 29, 29])\n",
      "out torch.Size([4, 20, 29, 29])\n",
      "in 2 AvgPool2d(kernel_size=2, stride=1, padding=1) torch.Size([4, 20, 29, 29])\n",
      "out torch.Size([4, 20, 30, 30])\n",
      "in 3 Conv2d(20, 19, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1)) torch.Size([4, 20, 30, 30])\n",
      "out torch.Size([4, 19, 31, 31])\n",
      "in 4 Tanh() torch.Size([4, 19, 31, 31])\n",
      "out torch.Size([4, 19, 31, 31])\n",
      "in 5 AvgPool2d(kernel_size=2, stride=2, padding=0) torch.Size([4, 19, 31, 31])\n",
      "out torch.Size([4, 19, 15, 15])\n",
      "in 6 Conv2d(19, 12, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1)) torch.Size([4, 19, 15, 15])\n",
      "out torch.Size([4, 12, 17, 17])\n",
      "in 7 ReLU() torch.Size([4, 12, 17, 17])\n",
      "out torch.Size([4, 12, 17, 17])\n",
      "in 8 MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False) torch.Size([4, 12, 17, 17])\n",
      "out torch.Size([4, 12, 9, 9])\n",
      "in 9 Conv2d(12, 15, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1)) torch.Size([4, 12, 9, 9])\n",
      "out torch.Size([4, 15, 11, 11])\n",
      "in 10 Sigmoid() torch.Size([4, 15, 11, 11])\n",
      "out torch.Size([4, 15, 11, 11])\n",
      "in 11 AvgPool2d(kernel_size=4, stride=2, padding=1) torch.Size([4, 15, 11, 11])\n",
      "out torch.Size([4, 15, 5, 5])\n",
      "in 12 Flatten(start_dim=1, end_dim=-1) torch.Size([4, 15, 5, 5])\n",
      "out torch.Size([4, 375])\n",
      "in 13 Linear(in_features=375, out_features=16, bias=True) torch.Size([4, 375])\n",
      "out torch.Size([4, 16])\n",
      "in 14 ReLU() torch.Size([4, 16])\n",
      "out torch.Size([4, 16])\n",
      "in 15 Linear(in_features=16, out_features=11, bias=True) torch.Size([4, 16])\n",
      "out torch.Size([4, 11])\n",
      "in 16 ReLU() torch.Size([4, 11])\n",
      "out torch.Size([4, 11])\n",
      "in 17 Linear(in_features=11, out_features=10, bias=True) torch.Size([4, 11])\n",
      "out torch.Size([4, 10])\n",
      "tensor([[ 0.3052,  0.2878,  0.0876, -0.1887,  0.2254,  0.0794, -0.0018, -0.0144,\n",
      "          0.2687, -0.1071],\n",
      "        [ 0.3052,  0.2880,  0.0874, -0.1888,  0.2258,  0.0799, -0.0022, -0.0141,\n",
      "          0.2687, -0.1069],\n",
      "        [ 0.3053,  0.2879,  0.0872, -0.1889,  0.2260,  0.0800, -0.0020, -0.0141,\n",
      "          0.2688, -0.1066],\n",
      "        [ 0.3053,  0.2878,  0.0874, -0.1888,  0.2257,  0.0796, -0.0017, -0.0143,\n",
      "          0.2687, -0.1069]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "images , classes = next(iter(trainloader))\n",
    "netcode = Net_encoding( 4, 2, 1, 10 , 28)\n",
    "model = Net(netcode)\n",
    "def imgshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "print(images.shape)\n",
    "imgshow(torchvision.utils.make_grid(images))\n",
    "print(classes)\n",
    "print(model(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net encoding len: 6\n",
      "module_types.FEATURES\n",
      "(<layer_type.CONV: 2>, {'kernel_size': 1, 'stride': 1, 'padding': 1}, {'in': 1, 'out': 17})\n",
      "(<layer_type.ACTIVATION: 3>, <activation.TANH: 3>, {'in': 17, 'out': 17})\n",
      "(<layer_type.POOLING: 1>, {'pool_type': <pool.AVG: 2>, 'kernel_size': 4, 'stride': 2, 'padding': 1}, {'in': 17, 'out': 17})\n",
      "param:  {'input_channels': 1, 'output_channels': 17}\n",
      "None\n",
      "module_types.FEATURES\n",
      "(<layer_type.CONV: 2>, {'kernel_size': 2, 'stride': 1, 'padding': 1}, {'in': 17, 'out': 8})\n",
      "(<layer_type.ACTIVATION: 3>, <activation.RELU: 1>, {'in': 8, 'out': 8})\n",
      "(<layer_type.POOLING: 1>, {'pool_type': <pool.AVG: 2>, 'kernel_size': 2, 'stride': 1, 'padding': 1}, {'in': 8, 'out': 8})\n",
      "param:  {'input_channels': 17, 'output_channels': 8}\n",
      "None\n",
      "module_types.FEATURES\n",
      "(<layer_type.CONV: 2>, {'kernel_size': 1, 'stride': 1, 'padding': 1}, {'in': 8, 'out': 24})\n",
      "(<layer_type.ACTIVATION: 3>, <activation.SIGMOID: 2>, {'in': 24, 'out': 24})\n",
      "(<layer_type.POOLING: 1>, {'pool_type': <pool.MAX: 1>, 'kernel_size': 3, 'stride': 2, 'padding': 1}, {'in': 24, 'out': 24})\n",
      "param:  {'input_channels': 8, 'output_channels': 24}\n",
      "None\n",
      "module_types.FEATURES\n",
      "(<layer_type.CONV: 2>, {'kernel_size': 1, 'stride': 1, 'padding': 1}, {'in': 24, 'out': 21})\n",
      "(<layer_type.ACTIVATION: 3>, <activation.TANH: 3>, {'in': 21, 'out': 21})\n",
      "(<layer_type.POOLING: 1>, {'pool_type': <pool.MAX: 1>, 'kernel_size': 2, 'stride': 2, 'padding': 1}, {'in': 21, 'out': 21})\n",
      "param:  {'input_channels': 24, 'output_channels': 21}\n",
      "None\n",
      "module_types.CLASSIFICATION\n",
      "(<layer_type.LINEAR: 4>, None, {'in': 1029, 'out': 11})\n",
      "(<layer_type.ACTIVATION: 3>, <activation.TANH: 3>, {'in': 11, 'out': 11})\n",
      "param:  {'input_channels': 1029, 'output_channels': 11}\n",
      "None\n",
      "module_types.LAST_LAYER\n",
      "(<layer_type.LINEAR: 4>, None, {'in': 11, 'out': 10})\n",
      "param:  {'input_channels': 11, 'output_channels': 10}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "netcode.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#test on cifar10 --- DO NOT RUN IF YOU WANT MINST\n",
    "#   trainloader, testloader, classes = cifar10()\n",
    "#  model = Net(Net_encoding(5, 2, 3, 10, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model with an architecture selected with the DENSER grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 21, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(21, 25, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(25, 17, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (7): Tanh()\n",
      "    (8): AvgPool2d(kernel_size=3, stride=1, padding=0)\n",
      "    (9): Conv2d(17, 27, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(27, 25, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (13): Tanh()\n",
      "    (14): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (15): Flatten(start_dim=1, end_dim=-1)\n",
      "    (16): Linear(in_features=18225, out_features=26, bias=True)\n",
      "    (17): Tanh()\n",
      "    (18): Linear(in_features=26, out_features=25, bias=True)\n",
      "    (19): Sigmoid()\n",
      "    (20): Linear(in_features=25, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net(Net_encoding(5, 2, 1, 10, 28))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train import train, eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 12500/12500 [01:11<00:00, 174.30it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:06<00:00, 360.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 87 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, trainloader, device=\"cpu\")\n",
    "eval(model, testloader, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class evolution():\n",
    "    def __init__(self, population_size=10, holdout=1, mating=True):\n",
    "        \"\"\"\n",
    "        initial function fun is a function to produce nets, used for the original population\n",
    "        scoring_function must be a function which accepts a net as input and returns a float\n",
    "        \"\"\"\n",
    "        self.population_size = population_size\n",
    "        self.population = []\n",
    "        for _ in range(population_size):\n",
    "            num_feat = np.random.randint(1, 10)\n",
    "            num_class = np.random.randint(1, 10)\n",
    "            self.population.append(Net_encoding(num_feat,num_class,1,10,28))\n",
    "\n",
    "        self.best_organism = self.population[-1]\n",
    "        self.best_score = self.scoring_function(self.best_organism)\n",
    "\n",
    "        self.holdout = max(1, int(holdout * population_size))\n",
    "\n",
    "        self.mating = True\n",
    "        \n",
    "\n",
    "    def generation(self):\n",
    "        scores = [self.scoring_function(x) for x in self.population]\n",
    "        self.population = [self.population[x] for x in np.argsort(scores)[::-1]]\n",
    "\n",
    "        # update best organism and respective accuracy\n",
    "        self.best_organism = copy.deepcopy(self.population[0])\n",
    "        self.best_score = sorted(scores)[-1]\n",
    "        \n",
    "        new_population = [self.best_organism] # Ensure best organism survives\n",
    "        for i in range(self.population_size - 1):\n",
    "            parent_1_idx = i % self.holdout\n",
    "            if self.mating:\n",
    "                parent_2_idx = min(self.population_size - 1, int(np.random.exponential(self.holdout)))\n",
    "            else:\n",
    "                parent_2_idx = parent_1_idx\n",
    "            offspring, _ = GA_crossover(self.population[parent_1_idx], self.population[parent_2_idx]) # to build new generation functions mate and mutate are called as well\n",
    "            new_population.append(offspring)\n",
    "        \n",
    "        self.population = new_population\n",
    "\n",
    "    def get_best_organism(self, repeats=1):        \n",
    "        return self.best_organism, self.best_score\n",
    "\n",
    "    def training_function(self, netcode, trainloader):\n",
    "        model = Net(netcode)\n",
    "        train(model, trainloader, device=\"cuda\")\n",
    "        return model\n",
    "\n",
    "    def scoring_function(self, modelcode):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model = self.training_function(modelcode, trainloader)\n",
    "        accuracy = eval(model, testloader, device=\"cuda\")\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1250/1250 [00:04<00:00, 262.98it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:04<00:00, 532.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the class which will handle evolution of the NNs\n",
    "curr_env = evolution( population_size=5, holdout=0.6, mating=True)\n",
    "\n",
    "# get current most suitable network (organism)\n",
    "best_net, score = curr_env.get_best_organism()\n",
    "acc = [score]\n",
    "best_nets = [best_net]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1250/1250 [00:06<00:00, 194.96it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:03<00:00, 634.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1250/1250 [00:04<00:00, 252.44it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:03<00:00, 770.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:03<00:00, 383.61it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:02<00:00, 845.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:03<00:00, 332.60it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:02<00:00, 1117.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:05<00:00, 213.05it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:04<00:00, 570.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n",
      "FEATURES\n",
      "Generation  0 's best network accuracy:  11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:03<00:00, 401.47it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:03<00:00, 692.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:03<00:00, 329.70it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:02<00:00, 1020.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:02<00:00, 512.28it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:02<00:00, 989.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:03<00:00, 362.54it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:03<00:00, 641.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1250/1250 [00:03<00:00, 381.59it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:03<00:00, 700.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n",
      "CLASSIFICATION\n",
      "CLASSIFICATION\n",
      "Generation  1 's best network accuracy:  11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:03<00:00, 338.78it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:03<00:00, 695.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:04<00:00, 307.77it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:03<00:00, 625.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training: 100%|██████████| 1250/1250 [00:03<00:00, 319.07it/s]\n",
      "evaluating: 100%|██████████| 2500/2500 [00:02<00:00, 1035.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training:   0%|          | 0/1250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x26 and 26908x15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m generations \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(generations):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     curr_env\u001b[39m.\u001b[39;49mgeneration()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     this_generation_best, score \u001b[39m=\u001b[39m curr_env\u001b[39m.\u001b[39mget_best_organism()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     best_nets\u001b[39m.\u001b[39mappend(this_generation_best)\n",
      "\u001b[1;32m/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb Cell 29\u001b[0m in \u001b[0;36mevolution.generation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgeneration\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     scores \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring_function(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation[x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39margsort(scores)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# update best organism and respective accuracy\u001b[39;00m\n",
      "\u001b[1;32m/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb Cell 29\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgeneration\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     scores \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring_function(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation[x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39margsort(scores)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# update best organism and respective accuracy\u001b[39;00m\n",
      "\u001b[1;32m/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb Cell 29\u001b[0m in \u001b[0;36mevolution.scoring_function\u001b[0;34m(self, modelcode)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_function(modelcode, trainloader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(model, testloader, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy\n",
      "\u001b[1;32m/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb Cell 29\u001b[0m in \u001b[0;36mevolution.training_function\u001b[0;34m(self, netcode, trainloader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_function\u001b[39m(\u001b[39mself\u001b[39m, netcode, trainloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     model \u001b[39m=\u001b[39m Net(netcode)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     train(model, trainloader, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Repository/Genetics_ANN/Architecture_selection/scripts/train.py:28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     27\u001b[0m \u001b[39m# calculate outputs by running images through the network\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     29\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     30\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_le/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb Cell 29\u001b[0m in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_list)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         \u001b[39m# print(\"in\", i,self.layer_list[i], x.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer_list[i](x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m         \u001b[39m# print(\"out\", x.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Repository/Genetics_ANN/Architecture_selection/03_DENSER.ipynb#X44sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_le/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_le/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x26 and 26908x15)"
     ]
    }
   ],
   "source": [
    "generations = 5\n",
    "for i in range(generations):\n",
    "    curr_env.generation()\n",
    "    this_generation_best, score = curr_env.get_best_organism()\n",
    "    best_nets.append(this_generation_best)\n",
    "    acc.append(score)\n",
    "    #if i%5==0:\n",
    "    print(\"Generation \", i , \"'s best network accuracy: \", score, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep_le')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a142b7d21e8575b7566c168744f24153333bb674c4e2523209192565d5391819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
