{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, randint, seed\n",
    "from statistics import mean\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import PIL.Image as Image\n",
    "from torchvision import datasets,models\n",
    "\n",
    "from sympy.solvers import solve\n",
    "from sympy import Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dowload the dataset\n",
    "# prepare a preprocessing pipeline \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "# We download the train and the test dataset in the given root and applying the given transforms\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,  download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,  download=True, transform=transform)\n",
    "\n",
    "batch_size=4\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,  shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,  shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, genotype):\n",
    "        super().__init__()\n",
    "        self.genotype = genotype\n",
    "        self.layerlist = []\n",
    "        self.input_channels = 1\n",
    "        self.output_channels = 6\n",
    "        self.output_size = 10\n",
    "        self.kernel_size = 5\n",
    "        self.input_size = 28\n",
    "        self.final_size = 7\n",
    "\n",
    "        self.build_layers(genotype)\n",
    "        self.layers = torch.nn.Sequential(*self.layerlist)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "    def build_layers(self, genotype):\n",
    "        for i, gene in enumerate(genotype): \n",
    "            # add final layer\n",
    "            if gene == 0:\n",
    "                # target output has the same size finalxfinal for each network\n",
    "                self.layerlist.append(torch.nn.AdaptiveAvgPool2d(self.final_size))\n",
    "                self.layerlist.append(torch.nn.Flatten())\n",
    "                size = self.output_channels*(self.final_size)**2\n",
    "                self.layerlist.append(torch.nn.Linear(size, 120))\n",
    "                self.layerlist.append(torch.nn.ReLU())\n",
    "                self.layerlist.append(torch.nn.Linear(120, 84))\n",
    "                self.layerlist.append(torch.nn.ReLU())\n",
    "                self.layerlist.append(torch.nn.Linear(84, self.output_size))\n",
    "\n",
    "            # add another intermediate layer\n",
    "            elif gene == 1:\n",
    "                output_channels = np.random.randint(1, 10)\n",
    "                if genotype[i+1] == 2:\n",
    "                    output_channels = 4 # here to be set not locally\n",
    "                   \n",
    "                kernel_size = np.random.randint(2, 5)\n",
    "                padding = 2\n",
    "                self.layerlist.append(torch.nn.Conv2d(in_channels=self.input_channels, out_channels=output_channels, kernel_size=kernel_size, stride=1, padding=padding))\n",
    "                self.layerlist.append(torch.nn.ReLU())\n",
    "                self.layerlist.append(torch.nn.MaxPool2d(2, 2))\n",
    "                self.input_size = int((self.input_size - kernel_size + 1 + padding*2)/2)\n",
    "                self.output_channels = output_channels\n",
    "                self.input_channels = output_channels\n",
    "                self.kernel_size = kernel_size\n",
    "\n",
    "            # add non-parametrizable block\n",
    "            elif gene == 2:\n",
    "                output_channels = 6\n",
    "                kernel_size = 3\n",
    "                padding = 2\n",
    "\n",
    "                self.layerlist.append(torch.nn.Conv2d(in_channels=4, out_channels=output_channels, kernel_size=kernel_size, stride=1, padding=padding))\n",
    "                self.layerlist.append(torch.nn.ReLU())\n",
    "                self.layerlist.append(torch.nn.MaxPool2d(2, 2))\n",
    "                self.input_size = int((self.input_size - kernel_size + 1 + padding*2)/2)\n",
    "                self.output_channels = output_channels\n",
    "                self.input_channels = output_channels\n",
    "                self.kernel_size = kernel_size\n",
    "\n",
    "    # mate function combines two networks by randomly selecting weights from one of the parents\n",
    "    def mate(self, other, mutate=True):\n",
    "        child = copy.deepcopy(self)\n",
    "        i = 0\n",
    "        while i < len(child.genotype):#for i in range(len(child.genotype)): # [1,1,2,0]\n",
    "          # change only blocks marked as \n",
    "            if self.genotype[i]==1:\n",
    "                pass_on = np.random.rand(1) < 0.5\n",
    "                while self.genotype[i]==1:\n",
    "                    for j in range(3): # 3 layers per block\n",
    "                        child.layers[i+j] = self.layers[i+j] if pass_on else other.layers[i+j]\n",
    "                    i += 1\n",
    "\n",
    "            elif self.genotype[i]==2:\n",
    "                pass_on = np.random.rand(1) < 0.5\n",
    "                for j in range(3): # 3 layers per block\n",
    "                    child.layers[i+j] = self.layers[i+j] if pass_on else other.layers[i+j]\n",
    "                    \n",
    "                i += 1\n",
    "            \n",
    "            elif self.genotype[i]==0:\n",
    "                pass_on = np.random.rand(1) < 0.5\n",
    "                for j in range(7): # 3 layers per block\n",
    "                    child.layers[i+j] = self.layers[i+j] if pass_on else other.layers[i+j]\n",
    "                    \n",
    "                i += 1\n",
    "\n",
    "        if mutate:\n",
    "            child.mutate(stdev=np.random.rand(1)/10)\n",
    "        return child\n",
    "\n",
    "    # the mutation step is realized as the addition of Gaussian noise to each weight in the network\n",
    "    def mutate(self, stdev=0.03):\n",
    "        for i in range(len(self.layers)):\n",
    "            if isinstance(self.layers[i], nn.Conv2d) or isinstance(self.layers[i], nn.Linear):\n",
    "              with torch.no_grad():\n",
    "                self.layers[i].weight +=  torch.tensor(np.random.normal(0,stdev, list(self.layers[i].weight.shape)))\n",
    "                self.layers[i].bias +=  torch.tensor(np.random.normal(0, stdev, list(self.layers[i].bias.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(4, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): AdaptiveAvgPool2d(output_size=7)\n",
       "    (7): Flatten(start_dim=1, end_dim=-1)\n",
       "    (8): Linear(in_features=294, out_features=120, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = ConvNet([1,2,0])\n",
    "m2 = ConvNet([1,2,0])\n",
    "\n",
    "m1.mate(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The net takes as input object with size:  torch.Size([4, 1, 28, 28])\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       20\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─MaxPool2d: 2-3                    --\n",
      "|    └─Conv2d: 2-4                       222\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─Conv2d: 2-7                       100\n",
      "|    └─ReLU: 2-8                         --\n",
      "|    └─MaxPool2d: 2-9                    --\n",
      "|    └─Conv2d: 2-10                      222\n",
      "|    └─ReLU: 2-11                        --\n",
      "|    └─MaxPool2d: 2-12                   --\n",
      "|    └─AdaptiveAvgPool2d: 2-13           --\n",
      "|    └─Flatten: 2-14                     --\n",
      "|    └─Linear: 2-15                      35,400\n",
      "|    └─ReLU: 2-16                        --\n",
      "|    └─Linear: 2-17                      10,164\n",
      "|    └─ReLU: 2-18                        --\n",
      "|    └─Linear: 2-19                      850\n",
      "=================================================================\n",
      "Total params: 46,978\n",
      "Trainable params: 46,978\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Conv2d: 2-1                       20\n",
       "|    └─ReLU: 2-2                         --\n",
       "|    └─MaxPool2d: 2-3                    --\n",
       "|    └─Conv2d: 2-4                       222\n",
       "|    └─ReLU: 2-5                         --\n",
       "|    └─MaxPool2d: 2-6                    --\n",
       "|    └─Conv2d: 2-7                       100\n",
       "|    └─ReLU: 2-8                         --\n",
       "|    └─MaxPool2d: 2-9                    --\n",
       "|    └─Conv2d: 2-10                      222\n",
       "|    └─ReLU: 2-11                        --\n",
       "|    └─MaxPool2d: 2-12                   --\n",
       "|    └─AdaptiveAvgPool2d: 2-13           --\n",
       "|    └─Flatten: 2-14                     --\n",
       "|    └─Linear: 2-15                      35,400\n",
       "|    └─ReLU: 2-16                        --\n",
       "|    └─Linear: 2-17                      10,164\n",
       "|    └─ReLU: 2-18                        --\n",
       "|    └─Linear: 2-19                      850\n",
       "=================================================================\n",
       "Total params: 46,978\n",
       "Trainable params: 46,978\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123456)\n",
    "\n",
    "# genotype can be whatever you want but it must finish with [2,0]\n",
    "model=ConvNet([1,2,1,2,0])\n",
    "\n",
    "dataloader_iterator = iter(trainloader)\n",
    "inputs, labels = next(dataloader_iterator)\n",
    "y = model(inputs)\n",
    "print(\"The net takes as input object with size: \", inputs.shape)\n",
    "summary(model, input_size=(1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network using SGD but without using all the training data at once\n",
    "def train(model, trainloader):\n",
    "    inspected = 50000\n",
    "    iterations = int(inspected / 4)\n",
    "\n",
    "    dataloader_iterator = iter(trainloader)\n",
    "\n",
    "    # define the loss function and the optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        try:\n",
    "            inputs, labels = next(dataloader_iterator)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        except StopIteration:\n",
    "            print(\"StopIteration, not enough data\")\n",
    "    \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at global performances on the testset\n",
    "def eval(model):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "  with torch.no_grad():\n",
    "      for data in testloader:\n",
    "          images, labels = data\n",
    "          # calculate outputs by running images through the network\n",
    "          outputs = model.forward(images)\n",
    "          # the class with the highest energy is what we choose as prediction\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct // total\n",
    "  print(f'Accuracy of the network on the 10000 test images: {accuracy} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 94 %\n"
     ]
    }
   ],
   "source": [
    "train(model, trainloader)\n",
    "eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class evolution():\n",
    "    def __init__(self, fun, population_size=10, holdout=1, mating=True):\n",
    "        \"\"\"\n",
    "        initial function fun is a function to produce nets, used for the original population\n",
    "        scoring_function must be a function which accepts a net as input and returns a float\n",
    "        \"\"\"\n",
    "        self.population_size = population_size\n",
    "        self.population = []\n",
    "        for _ in range(population_size):\n",
    "            torch.manual_seed(torch.randint(0, 100000, (1,)))\n",
    "            self.population.append(fun([1,2,0]))\n",
    "\n",
    "        self.best_organism = self.population[-1]\n",
    "        self.best_score = self.scoring_function(self.best_organism)\n",
    "\n",
    "        self.holdout = max(1, int(holdout * population_size))\n",
    "\n",
    "        self.mating = True\n",
    "        \n",
    "\n",
    "    def generation(self):\n",
    "        self.population = [train(self.population[0], trainloader) for x in self.population]\n",
    "        scores = [self.scoring_function(x) for x in self.population]\n",
    "        self.population = [self.population[x] for x in np.argsort(scores)[::-1]]\n",
    "\n",
    "        # update best organism and respective accuracy\n",
    "        self.best_organism = copy.deepcopy(self.population[0])\n",
    "        self.best_score = sorted(scores)[-1]\n",
    "        \n",
    "        new_population = [self.best_organism] # Ensure best organism survives\n",
    "        for i in range(self.population_size - 1):\n",
    "            parent_1_idx = i % self.holdout\n",
    "            if self.mating:\n",
    "                parent_2_idx = min(self.population_size - 1, int(np.random.exponential(self.holdout)))\n",
    "            else:\n",
    "                parent_2_idx = parent_1_idx\n",
    "            offspring = self.population[parent_1_idx].mate(self.population[parent_2_idx]) # to build new generation functions mate and mutate are called as well\n",
    "            new_population.append(offspring)\n",
    "        \n",
    "        self.population = new_population\n",
    "\n",
    "    def get_best_organism(self, repeats=1):        \n",
    "        return self.best_organism, self.best_score\n",
    "\n",
    "    def scoring_function(self, model):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = model.forward(images)\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "\n",
    "        accuracy = 100 * correct // total\n",
    "        return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to create the initial population\n",
    "net_creator = lambda g : ConvNet(g)\n",
    "\n",
    "# initialize the class which will handle evolution of the NNs\n",
    "curr_env = evolution(net_creator, population_size=4, holdout=0.6, mating=True)\n",
    "\n",
    "# get current most suitable network (organism)\n",
    "best_net, score = curr_env.get_best_organism()\n",
    "acc = [score]\n",
    "best_nets = [best_net]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       20\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─MaxPool2d: 2-3                    --\n",
      "|    └─Conv2d: 2-4                       222\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─Conv2d: 2-7                       55\n",
      "|    └─ReLU: 2-8                         --\n",
      "|    └─MaxPool2d: 2-9                    --\n",
      "|    └─Flatten: 2-10                     --\n",
      "|    └─Linear: 2-11                      3,120\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Linear: 2-13                      10,164\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Linear: 2-15                      850\n",
      "=================================================================\n",
      "Total params: 14,431\n",
      "Trainable params: 14,431\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Net  0 :\n",
      " =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       20\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─MaxPool2d: 2-3                    --\n",
      "|    └─Conv2d: 2-4                       222\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─Conv2d: 2-7                       55\n",
      "|    └─ReLU: 2-8                         --\n",
      "|    └─MaxPool2d: 2-9                    --\n",
      "|    └─Flatten: 2-10                     --\n",
      "|    └─Linear: 2-11                      3,120\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Linear: 2-13                      10,164\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Linear: 2-15                      850\n",
      "=================================================================\n",
      "Total params: 14,431\n",
      "Trainable params: 14,431\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       20\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─MaxPool2d: 2-3                    --\n",
      "|    └─Conv2d: 2-4                       222\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─Conv2d: 2-7                       225\n",
      "|    └─ReLU: 2-8                         --\n",
      "|    └─MaxPool2d: 2-9                    --\n",
      "|    └─Flatten: 2-10                     --\n",
      "|    └─Linear: 2-11                      27,120\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Linear: 2-13                      10,164\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Linear: 2-15                      850\n",
      "=================================================================\n",
      "Total params: 38,601\n",
      "Trainable params: 38,601\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Net  1 :\n",
      " =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       20\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─MaxPool2d: 2-3                    --\n",
      "|    └─Conv2d: 2-4                       222\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─Conv2d: 2-7                       225\n",
      "|    └─ReLU: 2-8                         --\n",
      "|    └─MaxPool2d: 2-9                    --\n",
      "|    └─Flatten: 2-10                     --\n",
      "|    └─Linear: 2-11                      27,120\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Linear: 2-13                      10,164\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Linear: 2-15                      850\n",
      "=================================================================\n",
      "Total params: 38,601\n",
      "Trainable params: 38,601\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       20\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─MaxPool2d: 2-3                    --\n",
      "|    └─Conv2d: 2-4                       222\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─Conv2d: 2-7                       100\n",
      "|    └─ReLU: 2-8                         --\n",
      "|    └─MaxPool2d: 2-9                    --\n",
      "|    └─Flatten: 2-10                     --\n",
      "|    └─Linear: 2-11                      12,120\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Linear: 2-13                      10,164\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Linear: 2-15                      850\n",
      "=================================================================\n",
      "Total params: 23,476\n",
      "Trainable params: 23,476\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Net  2 :\n",
      " =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       20\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─MaxPool2d: 2-3                    --\n",
      "|    └─Conv2d: 2-4                       222\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─Conv2d: 2-7                       100\n",
      "|    └─ReLU: 2-8                         --\n",
      "|    └─MaxPool2d: 2-9                    --\n",
      "|    └─Flatten: 2-10                     --\n",
      "|    └─Linear: 2-11                      12,120\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Linear: 2-13                      10,164\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Linear: 2-15                      850\n",
      "=================================================================\n",
      "Total params: 23,476\n",
      "Trainable params: 23,476\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       40\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─MaxPool2d: 2-3                    --\n",
      "|    └─Conv2d: 2-4                       222\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─Conv2d: 2-7                       679\n",
      "|    └─ReLU: 2-8                         --\n",
      "|    └─MaxPool2d: 2-9                    --\n",
      "|    └─Flatten: 2-10                     --\n",
      "|    └─Linear: 2-11                      13,560\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Linear: 2-13                      10,164\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Linear: 2-15                      850\n",
      "=================================================================\n",
      "Total params: 25,515\n",
      "Trainable params: 25,515\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Net  3 :\n",
      " =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       40\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─MaxPool2d: 2-3                    --\n",
      "|    └─Conv2d: 2-4                       222\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─Conv2d: 2-7                       679\n",
      "|    └─ReLU: 2-8                         --\n",
      "|    └─MaxPool2d: 2-9                    --\n",
      "|    └─Flatten: 2-10                     --\n",
      "|    └─Linear: 2-11                      13,560\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Linear: 2-13                      10,164\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Linear: 2-15                      850\n",
      "=================================================================\n",
      "Total params: 25,515\n",
      "Trainable params: 25,515\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# check different architectures\n",
    "for i,net in enumerate(curr_env.population):\n",
    "    print(\"Net \", i, \":\\n\",summary(net, input_size=(1, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation  0 's best network accuracy:  33 %\n",
      "Generation  1 's best network accuracy:  71 %\n",
      "Generation  2 's best network accuracy:  81 %\n",
      "Generation  3 's best network accuracy:  88 %\n",
      "Generation  4 's best network accuracy:  91 %\n"
     ]
    }
   ],
   "source": [
    "generations = 5\n",
    "for i in range(generations):\n",
    "    curr_env.generation()\n",
    "    this_generation_best, score = curr_env.get_best_organism()\n",
    "    best_nets.append(this_generation_best)\n",
    "    acc.append(score)\n",
    "    #if i%5==0:\n",
    "    print(\"Generation \", i , \"'s best network accuracy: \", score, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('deep-learn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d4df73e08e394aceedb93fd289f1fdb03087f2b8b3b3a9e1d14c5267e8bf280"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
