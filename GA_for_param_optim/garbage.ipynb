{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexserra98/miniconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import grammar as g\n",
    "import tmp as t\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramm = g.Grammar('/home/alexserra98/uni/prog_deep/Genetics_ANN/GA_for_param_optim/cnn.grammar.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features : [[('convolution', True), ('pooling', True)], [('convolution', True)], [('pooling', True)], [('pooling', True)], [('dropout', True)], [('batch-norm', True)]] \n",
      "\n",
      "convolution : [[('layer:conv', False), ('[num-filters,int,1,32,256]', False), ('[filter-shape,int,1,2,5]', False), ('[stride,int,1,1,3]', False), ('padding', True), ('activation-function', True), ('bias', True)]] \n",
      "\n",
      "batch-norm : [[('layer:batch-norm', False)]] \n",
      "\n",
      "pooling : [[('pool-type', True), ('[kernel-size,int,1,2,5]', False), ('[stride,int,1,1,3]', False), ('padding', True)]] \n",
      "\n",
      "pool-type : [[('layer:pool-avg', False)], [('layer:pool-max', False)]] \n",
      "\n",
      "padding : [[('padding:same', False)], [('padding:valid', False)]] \n",
      "\n",
      "dropout : [[('layer:dropout', False), ('[rate,float,1,0,0.7]', False)]] \n",
      "\n",
      "classification : [[('fully-connected', True)], [('dropout', True)]] \n",
      "\n",
      "fully-connected : [[('layer:fc', False), ('activation-function', True), ('[num-units,int,1,128,2048]', False), ('bias', True)]] \n",
      "\n",
      "activation-function : [[('act:linear', False)], [('act:relu', False)], [('act:sigmoid', False)]] \n",
      "\n",
      "bias : [[('bias:True', False)], [('bias:False', False)]] \n",
      "\n",
      "softmax : [[('layer:fc', False), ('act:softmax', False), ('num-units:10', False), ('bias:True', False)]] \n",
      "\n",
      "learning : [[('gradient-descent', True), ('early-stop', True), ('[batch_size,int,1,50,500]', False), ('epochs:400', False)], [('rmsprop', True), ('early-stop', True), ('[batch_size,int,1,50,500]', False), ('epochs:400', False)], [('adam', True), ('early-stop', True), ('[batch_size,int,1,50,500]', False), ('epochs:400', False)]] \n",
      "\n",
      "gradient-descent : [[('learning:gradient-descent', False), ('[lr,float,1,0.0001,0.1]', False), ('[momentum,float,1,0.68,0.99]', False), ('[decay,float,1,0.000001,0.001]', False), ('nesterov', True)]] \n",
      "\n",
      "nesterov : [[('nesterov:True', False)], [('nesterov:False', False)]] \n",
      "\n",
      "adam : [[('learning:adam', False), ('[lr,float,1,0.0001,0.1]', False), ('[beta1,float,1,0.5,1]', False), ('[beta2,float,1,0.5,1]', False), ('[decay,float,1,0.000001,0.001]', False)]] \n",
      "\n",
      "amsgrad : [[('amsgrad:True', False)], [('amsgrad:False', False)]] \n",
      "\n",
      "rmsprop : [[('learning:rmsprop', False), ('[lr,float,1,0.0001,0.1]', False), ('[rho,float,1,0.5,1]', False), ('[decay,float,1,0.000001,0.001]', False)]] \n",
      "\n",
      "early-stop : [[('[early_stop,int,1,5,20]', False)]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in gramm.grammar:\n",
    "    print(f'{i} : {gramm.grammar[i]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = gramm.initialise('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features : [{'ge': 2, 'ga': {}}]\n",
      "pooling : [{'ge': 0, 'ga': {'kernel-size': ('int', 2.0, 5.0, [3]), 'stride': ('int', 1.0, 3.0, [1])}}]\n",
      "pool-type : [{'ge': 0, 'ga': {}}]\n",
      "padding : [{'ge': 1, 'ga': {}}]\n"
     ]
    }
   ],
   "source": [
    "for i in prova:\n",
    "    print(f'{i} : {prova[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_layers = gramm.decode('features', prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pool-avg', {'kernel-size': ['3'], 'stride': ['1'], 'padding': ['valid']})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_decoding = t.Evaluator()\n",
    "l_dict = layer_decoding.get_layers(feat_layers) \n",
    "l_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'layer:pool-avg kernel-size:3 stride:1 padding:valid'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(l_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tmp' from '/home/alexserra98/uni/prog_deep/Genetics_ANN/GA_for_param_optim/tmp.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_type: pool-avg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assembler = t.Evaluator()\n",
    "lay = assembler.assemble_network(l_dict,(28,28,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.container.Sequential"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tmp' from '/home/alexserra98/uni/prog_deep/Genetics_ANN/GA_for_param_optim/tmp.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramm = g.Grammar('/home/alexserra98/uni/prog_deep/Genetics_ANN/GA_for_param_optim/cnn.grammar.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module = t.Module('features',1,10,)\n",
    "init_max = {'features' : 5,'classification' : 1, 'learning' : 1}\n",
    "my_module.initialise(gramm,0.2,init_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_layers_decoded = []\n",
    "for i in my_module.layers:\n",
    "    my_layers_decoded.append(gramm.decode('features', i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classification module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module1 = t.Module('classification',1,2)\n",
    "init_max = {'features' : 5,'classification' : 1, 'learning' : 1}\n",
    "my_module1.initialise(gramm,0.2,init_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'classification': [{'ge': 0, 'ga': {}}],\n",
       "  'fully-connected': [{'ge': 0,\n",
       "    'ga': {'num-units': ('int', 128.0, 2048.0, [992])}}],\n",
       "  'activation-function': [{'ge': 0, 'ga': {}}],\n",
       "  'bias': [{'ge': 0, 'ga': {}}]}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_module1.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_layers_decoded_1 = []\n",
    "for i in my_module1.layers:\n",
    "    my_layers_decoded_1.append(gramm.decode('classification', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_class =' '.join(my_layers_decoded_1)\n",
    "pheno_feat =' '.join(my_layers_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_decoding = t.Net_encoding(5,2,3,2,(28,28,3),pheno_feat,pheno_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_layer_list = layer_decoding.get_layers(pheno_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fc', {'act': ['tanh'], 'num-units': ['992'], 'bias': ['True']})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_type: fc\n"
     ]
    }
   ],
   "source": [
    "lay,size = layer_decoding.assemble_block(my_layer_list,2352)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module2 = t.Module('learning',1,2,)\n",
    "init_max = {'features' : 5,'classification' : 1, 'learning' : 1}\n",
    "my_module2.initialise(gramm,0.2,init_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_my_layers = my_layers_decoded + my_layers_decoded_1\n",
    "phenotype =' '.join(last_my_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_layer_list = layer_decoding.get_layers(phenotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_type: batch-norm\n",
      "layer_type: conv\n",
      "layer_type: dropout\n",
      "layer_type: dropout\n",
      "layer_type: conv\n",
      "layer_type: fc\n"
     ]
    }
   ],
   "source": [
    "lay = layer_decoding.assemble_model(pheno_feat,pheno_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genNN(\n",
       "  (fe): Sequential(\n",
       "    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(3, 203, kernel_size=(2, 2), stride=(1, 1), padding=valid)\n",
       "    (2): Sigmoid()\n",
       "    (3): Dropout2d(p=0.4968258204193914, inplace=False)\n",
       "    (4): Dropout2d(p=0.4968258204193914, inplace=False)\n",
       "    (5): Conv2d(203, 203, kernel_size=(2, 2), stride=(1, 1), padding=valid)\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       "  (c): Sequential(\n",
       "    (0): Linear(in_features=116928, out_features=992, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (last): Sequential(\n",
       "    (0): Linear(in_features=992, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes,fe,c):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fe(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.c(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return logits, probs\n",
    "\n",
    "feature_extractor = nn.Sequential(            \n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=120, out_features=84),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=84, out_features=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_object = LeNet5(10,feature_extractor,classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "273c48406751af6277a0bdb291ee674620b66e29f007a13179c473c693907be6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
